\documentclass[11pt,reqno]{amsart}
%============%============%============%============%

%============%============%============%============%
%\setlength{\columnseprule}{0.4pt}
%\setlength{\topmargin}{0cm}
%\setlength{\oddsidemargin}{.25cm}
%\setlength{\evensidemargin}{.25cm}
%\setlength{\textheight}{22.5cm}
%\setlength{\textwidth}{15.5cm}
\renewcommand{\baselinestretch}{1.05}
%============%============%============%============%
\usepackage[toc,page]{appendix}
%============%============%============%============%
%\usepackage{romannum}
\usepackage{xcolor}
\usepackage{placeins}
\usepackage{amsfonts,amsmath,amsthm}
\usepackage{amssymb,epsfig}
\usepackage{enumerate} 
\usepackage[notcite,notref]{showkeys}
\usepackage{fullpage}
%============%============%============%============%
\usepackage[utf8]{inputenc}
%\usepackage{mathpazo}

%\usepackage[libertine,cmintegrals,cmbraceFunction Analysis - Haim brezis.pdfFunction Analysis - Haim brezis.pdfFunction Analysis - Haim brezis.pdfFunction Analysis - Haim brezis.pdfFunction Analysis - Haim brezis.pdfFunction Analysis - Haim brezis.pdfFunction Analysis - Haim brezis.pdfFunction Analysis - Haim brezis.pdfFunction Analysis - Haim brezis.pdfs,vvarbb]{newtxmath}
\usepackage{eucal}
\usepackage[euler-digits]{eulervm}
\usepackage[unicode=true]{hyperref}
\hypersetup{colorlinks = true}
%\hypersetup{hidelinks=true}
\hypersetup{
     colorlinks,
     linkcolor={black!10!red},
     linkbordercolor = {black!100!red},
%    <your other options...>,
     citecolor={blue}
}





%graphic
%\usepackage[text={425pt,650pt},centering]{geometry}

\usepackage{pdfsync}

\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm,headheight=3.5cm}

\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{tikz}
\usepackage{caption}
\usepackage{color} %color
\definecolor{vert}{rgb}{0,0.6,0}

\usepackage{comment}
\numberwithin{figure}{section}
%\pagestyle{plain}


\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{ass}{Assumption}
\renewcommand{\theass}{}
\newtheorem{defn}{Definition}
\newtheorem{quest}{Question}
\newtheorem{com}{Comment}
\newtheorem{ex}{Example}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\theoremstyle{remark}
\newtheorem{rem}{\bf{Remark}}
\numberwithin{equation}{section}



%\renewcommand{\thefootnote}{\fnsymbol{footnote}}




%Characters -- Shortcuts
\newcommand{\E}{\mathbb{E}}
\newcommand{\M}{\mathbb{M}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\bP}{\mathbb{P}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\bS}{\mathbb{S}}
\newcommand{\T}{\mathbb{T}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\bfS}{\mathbf{S}}
\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\I}{\mathrm{I}}


%Functional spaces
\newcommand{\AC}{{\rm AC\,}}
\newcommand{\ACl}{{\rm AC}_{{\rm loc}}}
\newcommand{\BUC}{{\rm BUC\,}}
\newcommand{\USC}{{\rm USC\,}}
\newcommand{\LSC}{{\rm LSC\,}}
\newcommand{\Li}{L^{\infty}}
\newcommand{\Lip}{{\rm Lip\,}}
\newcommand{\W}{W^{1,\infty}}
\newcommand{\Wx}{W_x^{1,\infty}}


%Domains
\newcommand{\bO}{\partial\Omega}
\newcommand{\cO}{\overline\Omega}
\newcommand{\Q}{\mathbb{T}^{n}\times(0,\infty)}
\newcommand{\iQ}{\mathbb{T}^{n}\times\{0\}}
\newcommand{\cQ}{\mathbb{T}^{n}\times[0,\infty)}


%Greek alphabets -- Shortcuts
\newcommand{\al}{\alpha}
\newcommand{\gam}{\gamma}
\newcommand{\del}{\delta}
\newcommand{\ep}{\varepsilon}
\newcommand{\kap}{\kappa}
\newcommand{\lam}{\lambda}
\newcommand{\sig}{\sigma}
\newcommand{\om}{\omega}
\newcommand{\Del}{\Delta}
\newcommand{\Gam}{\Gamma}
\newcommand{\Lam}{\Lambda}
\newcommand{\Om}{\Omega}
\newcommand{\Sig}{\Sigma}



%Overlines, Underlines -- Shortcuts
\newcommand{\ol}{\overline}
\newcommand{\ul}{\underline}
\newcommand{\pl}{\partial}
\newcommand{\supp}{{\rm supp}\,}
\newcommand{\inter}{{\rm int}\,}
\newcommand{\loc}{{\rm loc}\,}
\newcommand{\co}{{\rm co}\,}
\newcommand{\diam}{{\rm diam}\,}
\newcommand{\diag}{{\rm diag}\,}
\newcommand{\dist}{{\rm dist}\,}
\newcommand{\Div}{{\rm div}\,}
\newcommand{\sgn}{{\rm sgn}\,}
\newcommand{\tr}{{\rm tr}\,}
\newcommand{\Per}{{\rm Per}\,}

\newcommand{\rmC}{\mathrm{C}}
\newcommand{\rup}{\rightharpoonup}


\renewcommand{\subjclassname}{%
\textup{2010} Mathematics Subject Classification} 

%Hyperlink in PDF file
%\usepackage[dvipdfm,
%  colorlinks=false,
%  bookmarks=true,
%  bookmarksnumbered=false,
%  bookmarkstype=toc]{hyperref}
%\makeatletter
%\def\@pdfm@dest#1{%
%  \Hy@SaveLastskip
%  \@pdfm@mark{dest (#1) [@thispage /\@pdfview\space @xpos @ypos null]}%
%  \Hy@RestoreLastskip
%}


%BibLatex
%\usepackage[
%backend=biber,
%style=alphabetic,
%sorting=ynt
%]{biblatex}
%\addbibresource{rate.bib}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{import}
\usepackage{xifthen}
\usepackage{pdfpages}
\usepackage{transparent}
\newcommand{\incfig}[1]{%
    \def\svgwidth{\columnwidth}
    \import{./figs/}{#1.pdf_tex}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\title[Rate of convergence]
{\textsc{Notes on the project}}
\thanks{The authors are supported in part by NSF grant DMS-1664424.}
%\begin{abstract}
%We investigate qualitatively the convergence of large, or state-constraint solution to nonlinear elliptic equation as the viscosity vanish.
%\end{abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author{Yuxi Han}
\address[Y. Han]
{
Department of Mathematics, 
University of Wisconsin Madison, 480 Lincoln  Drive, Madison, WI 53706, USA}
\email{yuxi.han@wisc.edu}
\author{Son N. T. Tu}
\address[S. N.T. Tu]
{
Department of Mathematics, 
University of Wisconsin Madison, 480 Lincoln  Drive, Madison, WI 53706, USA}
\email{thaison@math.wisc.edu}
\date{\today}
\keywords{first-order Hamilton--Jacobi equations; state-constraint problems; optimal control theory; rate of convergence; viscosity solutions.}
\subjclass[2010]{
35B40, %Asymptotic behavior of solutions, 
35D40, %Viscosity solutions
49J20, %Optimal control problems involving partial differential equations
49L25, %Viscosity solutions
70H20 %Hamilton-Jacobi equations
}
\maketitle
\setcounter{tocdepth}{1}
%\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Doubling variable - Attempt No. 28}
\noindent (February 14, 2021) \\
We invoke the following weird stuff, say (good news, it is proved in \cite{alessio_asymptotic_2006})
\begin{equation*}
 u^\varepsilon(x) \approx \frac{C_\varepsilon}{d(x)^\alpha} \qquad\text{as}\; x\to \partial\Omega\qquad \Longrightarrow\qquad Du^\varepsilon(x) \approx \frac{C_\varepsilon \alpha \nabla d(x)}{d(x)^{\alpha+1}} \qquad\text{as}\; x\to \partial\Omega.
\end{equation*}
Let us still use $\Omega = B(0,1)$, and also assume that $p\in \left(\frac{3}{2},2\right)$ so that $\alpha = \frac{2-p}{p-1} \in (0,1)$. We define
\begin{equation*}
    \Phi(x,y) = u^\varepsilon(x) - u_\delta(y) - \frac{C_\varepsilon |x-y|^2}{\sigma} - \frac{C_\varepsilon}{d(x)^{\alpha+1}}, \qquad (x,y)\in \overline{\Omega}\times \overline{\Omega}_\delta.
\end{equation*}
Let us start with $\Phi(x_\sigma,y_\sigma)\geq \Phi(0,y_\sigma)$, we have
\begin{align*}
    u^\varepsilon(x_\sigma) - u_\delta(y_\sigma) - \frac{C_\varepsilon |x_\sigma-y_\sigma|^2}{\sigma} - \frac{C_\varepsilon}{d(x_\sigma)^{\alpha+1}} \geq u^\varepsilon(0) - u_\delta(y_\sigma) - \frac{C_\varepsilon |y_\sigma|^2}{\sigma} - C_\varepsilon.
\end{align*}
Therefore
\begin{align*}
    \frac{C_\varepsilon |x_\sigma-y_\sigma|^2}{\sigma} + \frac{C_\varepsilon}{d(x_\sigma)^{\alpha+1}} &\leq C_\varepsilon + u^\varepsilon(x_\sigma) - u^\varepsilon(0) + \frac{C_\varepsilon }{\sigma}\\
    &\leq C_\varepsilon + \frac{C_\varepsilon}{\sigma} + \frac{C_\varepsilon \alpha|x_\sigma|}{d(x_\sigma)^{\alpha+1}}.
\end{align*}
As a consequence, since $\alpha \in (0,1)$ we have
\begin{equation*}
    \frac{C_\varepsilon |x_\sigma-y_\sigma|^2}{\sigma} + \frac{C_\varepsilon(1-\alpha)}{d(x_\sigma)^{\alpha+1}} 
    \leq C_\varepsilon + \frac{C_\varepsilon}{\sigma}.
\end{equation*}
Therefore
\begin{equation*}
    \frac{|x_\sigma - y_\sigma|^2}{\sigma} + \frac{(1-\alpha)}{d(x_\sigma)^{\alpha+1}} \leq 1 + \frac{1}{\sigma}.
\end{equation*}
Thus
\begin{equation*}
    \frac{\sigma(1-\alpha)}{d(x_\sigma)^{\alpha+1}} \leq \sigma+1
\end{equation*}
Therefore
\begin{equation*}
    d(x_\sigma)\geq \left(\left(\frac{1-\alpha}{1+\sigma}\right)\sigma\right)^{\frac{1}{\alpha+1}} 
\end{equation*}
Say let us try with $p = \frac{5}{3}$ so that $\alpha = \frac{1}{2}$, we have
\begin{equation*}
    d(x_\sigma) \geq \left(\frac{\sigma}{4}\right)^\frac{2}{3}.
\end{equation*}
Let $\sigma = 4\delta^\frac{3}{2}$ then $d(x_\sigma)\geq \delta$, therefore $\Phi(x_\sigma,y_\sigma)\geq \Phi(x_\sigma,x_\sigma)$, thus
\begin{equation*}
      u^\varepsilon(x_\sigma) - u_\delta(y_\sigma) - \frac{C_\varepsilon |x_\sigma-y_\sigma|^2}{\sigma} - \frac{C_\varepsilon}{d(x_\sigma)^{\alpha+1}} \geq u^\varepsilon(x_\sigma) - u_\delta(x_\sigma) - \frac{C_\varepsilon}{d(x_\sigma)^{\alpha+1}}
\end{equation*}
Therefore
\begin{equation}\label{e:bdd_xi}
    \frac{C_\varepsilon|x_\sigma - y_\sigma|^2}{\sigma} \leq u_\delta(x_\sigma) - u_\delta(y_\sigma)\leq C_0|x_\sigma - y_\sigma|
\end{equation}
Therefore
\begin{equation*}
    |x_\sigma - y_\sigma|\leq \left(\frac{C_0\alpha}{(\alpha+1)^{\alpha+1}}\right)\frac{\sigma}{\varepsilon^{\alpha+1}}.
\end{equation*}
Let $\sigma = \varepsilon^{(\alpha+1)(1+\beta)}$ for some $\beta > 0$. Then
\begin{equation*}
    |x_\sigma - y_\sigma|\leq \left(\frac{C_0\alpha}{(\alpha+1)^{\alpha+1}}\right)\varepsilon^{\beta(1+\alpha)} \qquad\text{and}\qquad d(x_\sigma)\geq \left(\frac{1-\alpha}{1+\sigma}\right)\varepsilon^{\beta}.
\end{equation*}
For simplicity, let us denote
\begin{equation*}
    K_4 = \left(\frac{C_0\alpha}{(\alpha+1)^{\alpha+1}}\right) \qquad\text{then}\qquad |x_\sigma-y_\sigma|\leq K_4\varepsilon^{\beta(1+\alpha)}.
\end{equation*}
Now $x\mapsto \Phi(x,y_\sigma)$ has a maximum at $x_\sigma\in \Omega$, i.e.,
    \begin{equation*}
        u^\varepsilon(x) - \left(\frac{C_\varepsilon|x-y_\sigma|^2}{\sigma} + \frac{C_\varepsilon}{d(x)^{\alpha+1}}\right)
    \end{equation*}
    has a maximum at $x_\sigma\in \Omega$. By subsolution test we have
\begin{align}\label{e:sub1}
    &\lambda u^\varepsilon(x_\sigma) + \left|\xi_\sigma+\zeta_\sigma\right|^p - f(x_\sigma)\nonumber\\
    &\quad  -\varepsilon\left(\frac{2nC_\varepsilon}{\sigma} + \frac{C_\varepsilon(\alpha+1)(\alpha+2)|D d(x_\sigma)|^2}{d(x_\sigma)^{\alpha+3}}-\frac{C_\varepsilon(\alpha+1)}{d(x_\sigma)^{\alpha+2}}\Delta d(x_\sigma)\right)  \leq 0
\end{align}
where 
\begin{equation}\label{e:est_xi_zeta}
    \xi_\sigma = \frac{2C_\varepsilon\big(x_\sigma-y_\sigma\big)}{\sigma} \qquad\text{and}\qquad \zeta_\sigma = - \frac{C_\varepsilon(\alpha+1)}{d(x_\sigma)^{\alpha+2}}D d(x_\sigma).
\end{equation}
We have the following estimates
\begin{align*}
    |\zeta_\sigma|=\left|\frac{C_\varepsilon(\alpha+1)}{d(x_\sigma)^{\alpha+2}}D d(x_\sigma )\right|
    &\leq \frac{C_\varepsilon(\alpha+1)}{\sigma^{\alpha+2}} = \frac{(\alpha+1)^{\alpha+2}}{\alpha}\left(\frac{1+\sigma}{1-\alpha}\right)^{\alpha+2}\left(\frac{\varepsilon^{\alpha+1}}{\varepsilon^{\beta(\alpha+2)}}\right).
\end{align*}
We need to choose $\beta$ such that
\begin{equation*}
 \displaystyle 0 < \beta < \frac{\alpha+1}{\alpha+2}.
\end{equation*}
In particular, we have
\begin{equation*}
    |\zeta_\sigma|\leq \mathfrak{C}_\alpha \qquad\text{where}\qquad \mathfrak{C}_\alpha =  \frac{(\alpha+1)^{\alpha+2}}{\alpha}\left(\frac{1+\sigma}{1-\alpha}\right)^{\alpha+2}.
\end{equation*}
On the other hand, from \eqref{e:bdd_xi} we have
\begin{equation*}
    |\xi_\sigma| = \frac{2C_\varepsilon|x_\sigma - y_\sigma|}{\sigma} \leq C_0 .
\end{equation*}
Now $y\mapsto \Phi^\sigma(x_\sigma,y)$ has a maximum at $y_\sigma\in \overline{\Omega}_\delta$, thus by supersolution test we have 
\begin{equation}\label{e:super1}
    \lambda u_\delta(y_\sigma) + \left|\xi_\sigma\right|^p - f(y_\sigma) \geq 0.
\end{equation}
Recall that $|D d(x_\sigma)| = 1$, from \eqref{e:sub1}, \eqref{e:super1}, $d(x_\sigma)\geq \sigma$ we have
\begin{align}
    &\lambda u^\varepsilon(x_\sigma) - \lambda u_\delta(y_\sigma) \leq |\xi_\sigma|^p - |\xi_\sigma+\zeta_\sigma|^p + f(y_\sigma) - f(x_\sigma) \nonumber\\
    &\qquad\qquad\qquad\quad + \varepsilon\left(\frac{2nC_\varepsilon}{\sigma} + \frac{C_\varepsilon(\alpha+1)(\alpha+2)}{d(x_\sigma)^{\alpha+3}} - \frac{C_\varepsilon(\alpha+1)\Delta d(x_\sigma)}{d(x_\sigma)^{\alpha+2}}\right)\nonumber \\
    &\qquad\qquad\qquad\quad\leq |\xi_\sigma|^p - |\xi_\sigma+\zeta_\sigma|^p + C_f|x_\sigma - y_\sigma| +\varepsilon \left(\frac{2n C_\varepsilon}{\sigma} + \frac{(\alpha+2)}{d(x_\sigma)}|\zeta_\sigma| + K_2|\zeta_\sigma|\right) \label{e:est3}
\end{align}
where $K_2 = \max_{x\in \overline{\Omega}}\Delta d(x)$. Using the estimate
\begin{align*}
    \left||x+y|^p - |x|^p \right| \leq  p\big(|x|+|y|\big)^{p-1}|y|
\end{align*}
with $x = \xi_\sigma$, $y = \zeta_\sigma$ and the fact that $|\zeta_\sigma|\leq \mathfrak{C}_\alpha$ we obtain
\begin{align}
    \Big||\xi_\sigma+\zeta_\sigma|^p - |\xi|^p\Big| &\leq p\Big(|\xi_\sigma|+|\zeta_\sigma|\Big)^{p-1}|\zeta_\sigma| \nonumber \\
    &\leq \Big( p(C_0 + \mathfrak{C}_\alpha)^{p-1}\mathfrak{C}_\alpha \Big) \varepsilon^{(\alpha+1) -\beta(\alpha+2)} \leq K_3\varepsilon ^{(\alpha+1)  - \beta(\alpha+2)}\label{e:est2}
\end{align}
where $K_3 = p\mathfrak{C}_\alpha(C_0+\mathfrak{C}_\alpha)^{p-1}$. From \eqref{e:est3} and \eqref{e:est2} we deduce that
\begin{align*}
    \lambda u^\varepsilon(x_\sigma) - \lambda u_\delta(y_\sigma) &\leq  K_3 \varepsilon^{(\alpha+1) - \beta(\alpha+2)}  + C_fK_4 \varepsilon^{\beta(1+\alpha)} \\
    &+ \left(\frac{2n(\alpha+1)^{\alpha+1}}{\alpha}\right)\varepsilon^{(\alpha+2) - (\alpha+1)(\beta+1)}\\
    &+ \left(\frac{(\alpha+2)(1+\sigma)}{1-\alpha}\mathfrak{C}_\alpha\right)\varepsilon^{(1-\beta) + (\alpha+1) - \beta(\alpha+2)}\\
    &+ K_2\mathfrak{C}_\alpha \varepsilon^{1+(\alpha+1)-\beta(\alpha+2)}.
\end{align*}
We obtain again that the optimal rate is $\mathcal{O}(\sqrt{\varepsilon})$ in this case.

\section{Questions and Ideas}
\begin{quest} [Jan 12, 2021] Why do we use the distance functions to get boundary estimates? 
\end{quest}

\begin{quest} [Jan 13, 2021] Maximum principle for sub-quadratic case.
\end{quest}

\begin{quest}[Jan 20, 2021] Here is an idea to estimate $\Vert u^\varepsilon - u^0\Vert_{L^\infty_{loc}(\Omega)}$. We start first by assuming star-shaped and consider
\begin{equation}\label{e:S_eta}
    \begin{cases}
    \lambda u_\eta^\varepsilon(x) + H(x,Du_\eta^\varepsilon(x)) - \varepsilon \Delta u_\eta^\varepsilon(x) = 0 &\qquad
    \text{in}\;(1-\eta)\Omega, \vspace{0cm}\\
    \qquad\qquad\qquad\qquad\qquad\qquad\;\, u^\varepsilon_\eta(x) = +\infty &\qquad
    \text{on}\;(1-\eta)\partial\Omega.
    \end{cases} \tag{$S_\eta$}
\end{equation}
Can we estimate $0\leq u^\varepsilon_\eta - u^\varepsilon \leq \omega(\varepsilon,\eta)$ and then chose $\eta = \omega'(\varepsilon)$ to conclude? One way is to approximate infinity boundary by finite boundary first, it may be too naive, but whatever! 
\begin{equation}\label{e:S_eta_m}
    \begin{cases}
    \lambda v_\eta^\varepsilon(x) + H(x,Dv_\eta^\varepsilon(x)) - \varepsilon \Delta v_\eta^\varepsilon(x) = 0 &\qquad
    \text{in}\;(1-\eta)\Omega, \vspace{0cm}\\
    \qquad\qquad\qquad\qquad\qquad\qquad\;\, v^\varepsilon_\eta(x) = m &\qquad
    \text{on}\;(1-\eta)\partial\Omega.
    \end{cases} \tag{$S_{\eta}^m$}
\end{equation}
In contrast, let us consider
\begin{equation}\label{e:S_0}
    \begin{cases}
    \lambda v^\varepsilon(x) + H(x,Dv^\varepsilon(x)) - \varepsilon \Delta v^\varepsilon(x) = 0 &\qquad
    \text{in}\;\Omega, \vspace{0cm}\\
    \qquad\qquad\qquad\qquad\qquad\qquad\;\, v^\varepsilon(x) = m &\qquad
    \text{on}\;\partial\Omega.
    \end{cases} \tag{$S^m$}
\end{equation}
How can we compare $v^\varepsilon$ and $v^\varepsilon_\eta$?
\end{quest}

\begin{quest} Let $g_{\varepsilon,\delta}(x) = u^\varepsilon(x)$ for $x\in \partial\Omega_\delta$ which is finite. We have $u_\delta\leq g_{\varepsilon,\delta}$ for all $\varepsilon$ and also for each fixed $\delta>0$ then
\begin{equation*}
    \lim_{\varepsilon\to 0} g_{\varepsilon,\delta}(x) = u_\delta(x).
\end{equation*}
On the domain $\Omega_\delta$, we consider the problem
\begin{equation*}
    \begin{cases}
    \mathcal{L}[v^\varepsilon] = 0 &\qquad\text{in}\;\Omega_\delta,\\
    v^\varepsilon = g_{\delta,\varepsilon} &\qquad\text{on}\;\partial\Omega_\delta.
    \end{cases}
\end{equation*}
Question: can we quantify $\Vert v^\varepsilon - u_\delta\Vert_{L^\infty}$ in term of $\varepsilon$?

\end{quest}


\color{blue}
\textcolor{blue}{\textbf{The next questions and tasks:}}
\begin{enumerate}
    \item Check all the constants, make sure things are correct!
    \item It seems that $\sqrt{\varepsilon}$ is the best using this method. Now we can improve this by either:
    \begin{itemize}
        \item[(a)] Make the boundary layer to $\sqrt{\varepsilon}$ only, instead of $2\sqrt{\varepsilon}$.
        \item[(b)] \textcolor{red}{\textbf{Important.}} Generalize this to more general domain, possibly star-shaped domains where we can do scaling is fine (just my guess).
    \end{itemize}
    \item Other formulations of the doubling variable method here, for example, in the first step, it seems that making $\Phi^\sigma(x,y)\to  -\infty$ as $x\to \partial\Omega$ is "\emph{too wasteful}". One may need only to do something like
    \begin{equation*}
        \Phi^\sigma(x,y) < \Phi^\sigma(0,0) \qquad\text{if}\qquad d(x) < \;\text{something close to the boundary}.
    \end{equation*}
    Can we improve that to get a better rate? My guess is not even if we can improve this, since the dominating term coming from $\varepsilon^\gamma$ and $\varepsilon^{1-\gamma}$ later. Nevertheless, it maybe still interesting to see why and how the \emph{wasteful} formulation here can be improved.
    \item \textcolor{red}{\textbf{Important.}} Using nonlinear adjoint method.
    \item Now once we have some rate, can we do bootstrap to improve it as we discussed earlier (the simple ideas, ...)?
    \item \textcolor{red}{\textbf{Important.}} Can we find an example where $|u^\varepsilon - u^0| = \mathcal{O}(1)$ in the strip where $0<\mathrm{dist}(x,\partial\Omega)<2\sqrt{\varepsilon}$? Or can we even make more layers inside with more scales, as $|u^\varepsilon - u^0| = \mathcal{O}(1)$ is not possible near the boundary $\partial\Omega$.
\end{enumerate}
\color{black}



\section{Gradient bounds}
\subsection{Local interior gradient bound for elliptic equation}
Let $\Omega\subset \R^n$ be an open, bounded, connected set with $\rmC^2$ boundary and $H(x,p):\overline{\Omega}\times \R^n\rightarrow \mathbb{R}$ be a continuously differentiable Hamiltonian satisfying
\begin{equation}\label{eq:grow}
\lim_{|p\rightarrow \infty} \left(\frac{1}{2}H(x,p)^2 + D_xH(x,p)\cdot p\right) = +\infty \qquad\text{uniformly in}\;x\in \overline{\Omega}. \tag{H1}
\end{equation}
We consider the following equation
\begin{equation}\label{eq:C_eps}
    \lambda u^\varepsilon(x) + H(x,Du^\varepsilon(x)) - \varepsilon \Delta u^\varepsilon(x) = 0 \qquad\text{in}\;\Omega.
\end{equation}
Let $u^\varepsilon\in \rmC^2(\Omega)\cap \mathrm{C}^1(\overline{\Omega})$ be a bounded solution to \eqref{eq:C_eps}, say $|\lambda u^\varepsilon(x)| \leq C_1$ for all $x\in \overline{\Omega}$. In this section we show that an interior gradient bound also holds, i.e., if $x\mapsto|Du^\varepsilon(x)|$ has a maximum over $\overline{\Omega}$ at $x_0\in \Omega$ then $|Du^\varepsilon(x_0)| \leq C_2$ for all $x\in \Omega$. Here $C_1,C_2$ are independent of $\varepsilon>0$.\\


\noindent We will use the classical Bernstein's argument. Let $\varphi(x) = \frac{1}{2}|Du^\varepsilon(x)|^2$ for $x\in \Omega$. Differentiate \eqref{eq:C_eps} in $x_i$ then multiply the resulting equation with $u^\varepsilon_{x_i}$ and then sum over $i=1,2,\ldots, n$ we obtain 
\begin{equation*}
    2\lambda \varphi(x) + D_pH(x,Du^\varepsilon(x))\cdot D\varphi(x) - \varepsilon \Delta \varphi(x) + \Big(\varepsilon |D^2u^\varepsilon(x)| + D_xH(x,Du^\varepsilon(x))\cdot Du^\varepsilon(x)\Big) = 0.
\end{equation*}
If $\varphi(x)$ achieves its maximum over $\overline{\Omega}$ at $x_0\in \Omega$, then $D\varphi(x_0) = 0$ and $\Delta \varphi(x_0)\leq 0$, together with $\varepsilon |D^2u^\varepsilon(x)|^2\geq \frac{1}{n\varepsilon}(\varepsilon\Delta u^\varepsilon(x))^2\geq (\varepsilon\Delta u^\varepsilon(x))^2$ if $n\varepsilon < 1$ we deduce that
\begin{equation*}
    \lambda |D u^\varepsilon(x_0)|^2 + \Big(\lambda u^\varepsilon(x_0)+H(x_0,Du^\varepsilon(x_0))\Big)^2 + D_xH(x_0,Du^\varepsilon(x_0))\cdot Du^\varepsilon(x_0) \leq 0.
\end{equation*}
Assume $|\lambda u^\varepsilon(x_0)|\leq C_1$, using \eqref{eq:grow} we deduce that
\begin{equation*}
    \frac{1}{2}H(x_0,Du^\varepsilon(x_0))^2 + D_xH(x_0,Du^\varepsilon(x_0))\cdot Du^\varepsilon(x_0) + \left(\frac{1}{\sqrt{2}}H(x_0,Du^\varepsilon(x_0) - \sqrt{2}C_1\right)^2 - \left(C_1\right)^2\leq 0
\end{equation*}
which gives us $|Du^\varepsilon(x_0)|\leq C_2$ for some $C_2$ independent of $\varepsilon$. 
\begin{rem} Assumption \eqref{eq:grow} is weaker than the combination of $p\mapsto H(x,p)$ is superlinear and $|D_xH(x,p)|\leq C(1+|p|)$.
\end{rem}


\section{The construction of $C^2$ diffeomorphism from $\overline{\Omega}$ to $\overline{\Omega^\delta}$}
$\Omega \subset \mathbb{R}^n$ is an open and bounded domain with a smooth boundary. For $\delta > 0$, let $\Gamma_\delta = \{x \in \Omega: \mathrm{dist}(x, \partial \Omega) < \delta \}$, $\Gamma^\delta = \{x \in \Omega^c: \mathrm{dist}(x, \Omega^c) < \delta \}$. For $\delta$ small enough, we want to construct a diffeomorphism $T_\delta$ that maps from $\overline{\Omega}$ onto $\overline{\Omega^\delta}$and $\partial \Omega$ onto $\partial \Omega^\delta$, and

$$\sup_{x\in \overline{\Omega}}\{|T_\delta(x)-x|+|\nabla T_\delta(x)-I|\} \leq C \delta.$$


The conditions on $\Omega$ imply that $\partial \Omega$ satisfies a uniform two-sided (interior and exterior) sphere condition. That is, at each point $y^0 \in \partial \Omega$, there exists a ball $B_1(r_{y_0}, y_0)$ such that $B_1(r_{y_0}, y_0) \cap (\mathbb{R}^n - \Omega)=\{y_0\}$, and another ball $B_2(r^\prime_{y_0}, y_0)$ such that $B_2(r^\prime_{y_0}, y_0) \cap  \Omega=B_2(r^\prime_{y_0}, y_0)$. More importantly, the radii are strictly bounded below by a positive constant, which we take to be $\delta$. Note that principal curvatures of $\partial \Omega$ are bounded by $\delta^{-1}$. 

For each point $z \in \Gamma_\delta$, there is a unique point $y=y(z) \in \partial \Omega$ such that $|y-z|=\mathrm{dist}(z, \partial \Omega)$, and for each point $x \in \Gamma^\delta$, there is a unique point $w=w(x) \in \partial \Omega$ such that $|w-x|= \mathrm{dist}(x, \partial \Omega)$.

Define a smooth increasing function $f: \mathbb{R} \to \mathbb{R}$ by

\begin{equation}
f(x)=\left\{  
   \begin{aligned}
   x, \, x \leq -\delta\\
   \delta, \, \, x=0.
  \end{aligned}
\right.
\end{equation}

Given a point $z_0 \in \Gamma_\delta$, let $y_0= y(z_0)$ and choose a principle coordinate system at $y_0$ for a neighborhood $\mathcal{N}(y_0)$ around $y_0$. Let $T(y_0)$ be the tangent hyperplane to $\partial \Omega$ at $y_0$ and $\mathbf{v}(y_0)$ be the inner normal vector to $\partial \Omega$ at $y_0$. In $\mathcal{N}(y_0)$ , $\partial \Omega$ is given by $x_n=\phi(x^\prime)$ where $x^\prime=(x_1, x_2, \cdots, x_n)$ for some smooth function $\phi$.

We define a map $g: (T(y_0) \times \mathcal{N}(y_0)) \times \mathbb{R} \to R^n $ by
$$g(z)=(y(z), \phi (y(z))) + f(|y(z)-z|) \mathbf{v}(y(z))$$

Define $\Gamma_\delta : \overline{\Omega} \to \overline{\Omega^\delta}$ by


%\section*{Acknowledgement}




\bibliography{zzzzlibrary}{}
%\bibliographystyle{ieeetr}
\bibliographystyle{acm}










\end{document}