\documentclass[11pt,reqno]{amsart}
%============%============%============%============%

%============%============%============%============%
%\setlength{\columnseprule}{0.4pt}
%\setlength{\topmargin}{0cm}
%\setlength{\oddsidemargin}{.25cm}
%\setlength{\evensidemargin}{.25cm}
%\setlength{\textheight}{22.5cm}
%\setlength{\textwidth}{15.5cm}
\renewcommand{\baselinestretch}{1.05}
%============%============%============%============%
\usepackage[toc,page]{appendix}
%============%============%============%============%
%\usepackage{romannum}
\usepackage{xcolor}
\usepackage{placeins}
\usepackage{amsfonts,amsmath,amsthm}
\usepackage{amssymb,epsfig}
\usepackage{enumerate} 
\usepackage[notcite,notref]{showkeys}
\usepackage{fullpage}
%============%============%============%============%
\usepackage[utf8]{inputenc}
%\usepackage{mathpazo}

%\usepackage[libertine,cmintegrals,cmbraceFunction Analysis - Haim brezis.pdfFunction Analysis - Haim brezis.pdfFunction Analysis - Haim brezis.pdfFunction Analysis - Haim brezis.pdfFunction Analysis - Haim brezis.pdfFunction Analysis - Haim brezis.pdfFunction Analysis - Haim brezis.pdfFunction Analysis - Haim brezis.pdfFunction Analysis - Haim brezis.pdfs,vvarbb]{newtxmath}
\usepackage{eucal}
\usepackage[euler-digits]{eulervm}
\usepackage[unicode=true]{hyperref}
\hypersetup{colorlinks = true}
%\hypersetup{hidelinks=true}
\hypersetup{
     colorlinks,
     linkcolor={black!10!red},
     linkbordercolor = {black!100!red},
%    <your other options...>,
     citecolor={blue}
}





%graphic
%\usepackage[text={425pt,650pt},centering]{geometry}

\usepackage{pdfsync}

\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm,headheight=3.5cm}

\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{tikz}
\usepackage{caption}
\usepackage{color} %color
\definecolor{vert}{rgb}{0,0.6,0}

\usepackage{comment}
\numberwithin{figure}{section}
%\pagestyle{plain}


\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{ass}{Assumption}
\renewcommand{\theass}{}
\newtheorem{defn}{Definition}
\newtheorem{quest}{Question}
\newtheorem{com}{Comment}
\newtheorem{ex}{Example}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\theoremstyle{remark}
\newtheorem{rem}{\bf{Remark}}
\numberwithin{equation}{section}



%\renewcommand{\thefootnote}{\fnsymbol{footnote}}




%Characters -- Shortcuts
\newcommand{\E}{\mathbb{E}}
\newcommand{\M}{\mathbb{M}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\bP}{\mathbb{P}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\bS}{\mathbb{S}}
\newcommand{\T}{\mathbb{T}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\bfS}{\mathbf{S}}
\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\I}{\mathrm{I}}


%Functional spaces
\newcommand{\AC}{{\rm AC\,}}
\newcommand{\ACl}{{\rm AC}_{{\rm loc}}}
\newcommand{\BUC}{{\rm BUC\,}}
\newcommand{\USC}{{\rm USC\,}}
\newcommand{\LSC}{{\rm LSC\,}}
\newcommand{\Li}{L^{\infty}}
\newcommand{\Lip}{{\rm Lip\,}}
\newcommand{\W}{W^{1,\infty}}
\newcommand{\Wx}{W_x^{1,\infty}}


%Domains
\newcommand{\bO}{\partial\Omega}
\newcommand{\cO}{\overline\Omega}
\newcommand{\Q}{\mathbb{T}^{n}\times(0,\infty)}
\newcommand{\iQ}{\mathbb{T}^{n}\times\{0\}}
\newcommand{\cQ}{\mathbb{T}^{n}\times[0,\infty)}


%Greek alphabets -- Shortcuts
\newcommand{\al}{\alpha}
\newcommand{\gam}{\gamma}
\newcommand{\del}{\delta}
\newcommand{\ep}{\varepsilon}
\newcommand{\kap}{\kappa}
\newcommand{\lam}{\lambda}
\newcommand{\sig}{\sigma}
\newcommand{\om}{\omega}
\newcommand{\Del}{\Delta}
\newcommand{\Gam}{\Gamma}
\newcommand{\Lam}{\Lambda}
\newcommand{\Om}{\Omega}
\newcommand{\Sig}{\Sigma}



%Overlines, Underlines -- Shortcuts
\newcommand{\ol}{\overline}
\newcommand{\ul}{\underline}
\newcommand{\pl}{\partial}
\newcommand{\supp}{{\rm supp}\,}
\newcommand{\inter}{{\rm int}\,}
\newcommand{\loc}{{\rm loc}\,}
\newcommand{\co}{{\rm co}\,}
\newcommand{\diam}{{\rm diam}\,}
\newcommand{\diag}{{\rm diag}\,}
\newcommand{\dist}{{\rm dist}\,}
\newcommand{\Div}{{\rm div}\,}
\newcommand{\sgn}{{\rm sgn}\,}
\newcommand{\tr}{{\rm tr}\,}
\newcommand{\Per}{{\rm Per}\,}

\newcommand{\rmC}{\mathrm{C}}
\newcommand{\rup}{\rightharpoonup}


\renewcommand{\subjclassname}{%
\textup{2010} Mathematics Subject Classification} 

%Hyperlink in PDF file
%\usepackage[dvipdfm,
%  colorlinks=false,
%  bookmarks=true,
%  bookmarksnumbered=false,
%  bookmarkstype=toc]{hyperref}
%\makeatletter
%\def\@pdfm@dest#1{%
%  \Hy@SaveLastskip
%  \@pdfm@mark{dest (#1) [@thispage /\@pdfview\space @xpos @ypos null]}%
%  \Hy@RestoreLastskip
%}


%BibLatex
%\usepackage[
%backend=biber,
%style=alphabetic,
%sorting=ynt
%]{biblatex}
%\addbibresource{rate.bib}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{import}
\usepackage{xifthen}
\usepackage{pdfpages}
\usepackage{transparent}
\newcommand{\incfig}[1]{%
    \def\svgwidth{\columnwidth}
    \import{./figs/}{#1.pdf_tex}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\title[Rate of convergence]
{\textsc{Second-order state-constraint Hamilton-Jacobi equations}}
\thanks{The authors are supported in part by NSF grant DMS-1664424.}
\begin{abstract}
We investigate qualitatively the convergence of large, or state-constraint solution to nonlinear elliptic equation as the viscosity vanish.
\end{abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author{Yuxi Han}
\address[Y. Han]
{
Department of Mathematics, 
University of Wisconsin Madison, 480 Lincoln  Drive, Madison, WI 53706, USA}
\email{yuxi.han@wisc.edu}
\author{Son N. T. Tu}
\address[S. N.T. Tu]
{
Department of Mathematics, 
University of Wisconsin Madison, 480 Lincoln  Drive, Madison, WI 53706, USA}
\email{thaison@math.wisc.edu}
\date{\today}
\keywords{first-order Hamilton--Jacobi equations; state-constraint problems; optimal control theory; rate of convergence; viscosity solutions.}
\subjclass[2010]{
35B40, %Asymptotic behavior of solutions, 
35D40, %Viscosity solutions
49J20, %Optimal control problems involving partial differential equations
49L25, %Viscosity solutions
70H20 %Hamilton-Jacobi equations
}
\maketitle
\setcounter{tocdepth}{1}
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:intro}
\subsection{Motivation} Let $\Omega$ be an open, bounded and connected with $\mathrm{C}^2$ boundary domain of $\mathbb{R}^n$. Let us consider the following Hamiltonian $ H(x,\varrho) = |\varrho|^p-f(x)$ for $(x,p)\in \overline{\Omega}\times \mathbb{R}^n$, $f\in \mathrm{C}(\overline{\Omega})\cap W^{1,\infty}(\Omega)$. Let $u^\varepsilon\in \mathrm{C}^2(\Omega)$ (see \cite{Lasry1989}) be the solution to 
\begin{equation}\label{eq:PDEeps}
    \begin{cases}
    \lambda u^\varepsilon(x) + H(x,Du^\varepsilon(x)) - \varepsilon \Delta u^\varepsilon(x) = 0 \qquad
    \text{in}\;\Omega, \vspace{0cm}\\
    \displaystyle  \lim_{\mathrm{dist}(x,\partial \Omega)\to 0} u^\varepsilon(x) = +\infty.
    \end{cases} \tag{PDE$_\varepsilon$}
\end{equation}
When $1<p\leq 2$, equation \eqref{eq:PDEeps} describes the (expectation) value function associated with a minimization of a stochastic optimal control problem with state-constraint. We are interested in studying the asymptotic behavior of $\{u^\varepsilon\}_{\varepsilon>0}$ as $\varepsilon\rightarrow 0$. Heuristically, the state-constraint second-order problem converges to the state-constraint first-order, which is associated with deterministic optimal control, which is described in the framework of viscosity solution as follows:
\begin{equation}\label{eq:PDE0}
    \begin{cases}
     \lambda u(x) + H(x,Du(x)) \leq 0\;\qquad\text{in}\;\Omega,\\
     \lambda u(x) + H(x,Du(x)) \geq 0\;\qquad\text{on}\;\overline{\Omega}.
    \end{cases} \tag{PDE$_0$}
\end{equation}
Equation \eqref{eq:PDE0} admits a unique viscosity solution in the space $\rmC(\overline{\Omega})$, which is also the maximal viscosity subsolution among all viscosity subsolution $v\in\rmC(\overline{\Omega})$. The problem is interesting since in the limit we no longer have blowing up behavior. In this paper, we are interested in the rate of convergence of $u^\varepsilon \to u$ as $\varepsilon\to 0$. A boundary layer is expected to describe the behavior of this convergence near the boundary.
\subsection{Assumptions} We will always assume $\Omega$ is an open, bounded and connected with $\mathrm{C}^2$ boundary in $\mathbb{R}^n$ and $H:\mathbb{R}^n\times \mathbb{R}^n$ is a continuous Hamiltonian. 
\begin{itemize}
    \item[$\mathrm{(A1)}$] $H(x,\varrho) = |\varrho|^p - f(x)$ where $1<p\leq 2$ and $f\in \mathrm{C}(\overline{\Omega})\cap W^{1,\infty}(\Omega)$.
\end{itemize}
We list the assumptions on a general Hamiltonian as follow.
\begin{itemize}
    \item[$\mathrm{(H1)}$] There exists $C_1 > 0$ such that $H(x,p) \geq -C_1$ for all $(x,p)\in \overline{\Omega}\times\mathbb{R}^n$.
    \item[$\mathrm{(H2)}$] There exists $C_2>0$ such that $|H(x,0)|\,\leq \,C_2$ for all $(x,p)\in \overline{\Omega}\times \mathbb{R}^n$.
    \item[$\mathrm{(H3)}$] For each $R>0$ there exists a modulus $\omega_{R}[0,\infty)\to [0,\infty)$ such that $\omega_R(0^+) = 0$ and 
    \begin{equation*}
        \begin{cases}
        |H(x,p) - H(y,p)| \leq \omega_R(|x-y|),\\
        |H(x,p) - H(x,q)| \leq \omega_R(|p-q|),
        \end{cases} \qquad\text{for all}\;x,y\in \overline{\Omega}, p,q \in \mathbb{R}^n\;\text{with}\;|p|,|q|\leq R.
    \end{equation*}
    \item[$\mathrm{(H4)}$] $H(x,p)\rightarrow \infty$ as $|p|\to \infty$ uniformly in $x\in \overline{\Omega}$.
\end{itemize}

\section{Preliminaries}\label{sec:prelim} 
\subsection{Setting and simplifications} Let $\Omega$ be an open, bounded and connected subset of $\mathbb{R}^n$ with boundary $\partial\Omega$ is of class $C^2$. For small $\delta>0$, we denote $\Omega_\delta = \{x\in \Omega: \mathrm{dist}(x,\Omega) > \delta\}$ and $\Omega^\delta = \{x\in \mathbb{R}^n: \mathrm{dist}(x,\overline{\Omega}) < \delta\}$. 
\begin{figure}[ht]
    \centering
    %\incfig{Domains}
    \def\svgwidth{0.47\columnwidth}
    \import{./figs/}{Domains.pdf_tex}
    \caption{The domain $\Omega$ variations $\Omega_\delta, \Omega^\delta$.}
    \label{fig:Domains}
\end{figure}


\noindent Let $\delta_0>0$ be a fixed number such that $x\mapsto \mathrm{dist}(x,\partial\Omega)$ is of class $\mathrm{C}^2$ on $\Omega\backslash \Omega_{\delta_0}$ (see \cite{gilbarg_elliptic_2001}), i.e., in the region where $0<\mathrm{dist}(x,\partial\Omega) \leq \delta_0$. We then extend $\mathrm{dist}(x,\partial\Omega)$ to a function $d(x)\in \mathrm{C}^2(\mathbb{R}^n)$ such that 
\begin{equation}\label{e:distance_def}
    \begin{cases}
    d(x)\geq 0\;\text{for}\;x\in\Omega\;\text{with}\;d(x) = +\mathrm{dist}(x,\partial\Omega)\;\text{for}\;x\in \Omega\backslash \Omega_{\delta_0},\\
    d(x)\leq 0\;\text{for}\;x\notin \Omega\;\text{with}\;d(x) = -\mathrm{dist}(x,\partial\Omega)\;\text{for}\;x\in \Omega^{\delta_0}\backslash \Omega.
    \end{cases}
\end{equation}
We recall that $|D d(x)| = 1$ in the viscosity sense (and thus in classical sense) in $\Omega^{\delta_0}\backslash \Omega_{\delta_0}$. Since $x\mapsto \mathrm{dist}(x,\partial \Omega)$ is a viscosity solution to $|Du(x)|=1$ in $\Omega$. %we can assume that the extension $d(x)$ as also satisfies $|Dd(x)|\leq 1$ in $\Omega$. 
Let 
\begin{equation*}
    K_1 := \max_{x\in \overline{\Omega}} |\Delta d(x)| \qquad\text{and}\qquad K_2 := \max_{x\in \overline{\Omega}} |D d(x)|.
\end{equation*}
\noindent We denote by $\mathcal{L}^\varepsilon:\rmC^2(\Omega)\to \rmC^2(\Omega)$ the elliptic operator
\begin{equation*}
    \mathcal{L}^\varepsilon[u](x) := \lambda u(x) + H(x,Du(x)) - \varepsilon \Delta u(x), \qquad x\in \Omega.
\end{equation*}



\subsection{Local gradient estimate} 
We recall the local gradient bound following \cite[Appendix]{Lasry1989}. The technique being used is the classical Bernstein's method. Let $\Omega$ be an open, bounded subset of $\R^n$, $\varepsilon \in (0,1)$ and $\lambda \in [0,1)$. We consider the Hamiltonian $H(x,\rho) = |\rho|^p - f(x)$ where $1<p < \infty$.

\begin{thm}\label{thm:grad_1} Let $f\in \rmC(\overline{\Omega})\cap W^{1,\infty}(\Omega)$ and $u\in \mathrm{C}^2(\Omega)$ be a solution to $\mathcal{L}^\varepsilon[u] = 0$ in $\Omega$. Assume that $\lambda u(x)-f(x)\geq -K_0$ in $\Omega$, then for $\delta>0$ there exists $C_\delta = C(K_0,p,\delta, \Vert D f\Vert_{L^\infty(\Omega)})$ such that 
\begin{equation*}
    \sup_{x\in \overline{\Omega}_\delta} \Big(|u(x)|+|Du(x)|\Big) \leq C_\delta.
\end{equation*}
\end{thm}

\begin{proof} Let $\theta\in (0,1)$ be chosen later, $\varphi\in \mathrm{C}_c^\infty(\Omega)$, $0\leq \varphi\leq 1$, $\mathrm{supp}\;\varphi\subset \Omega$ and $\varphi = 1$ on $\Omega_\delta$ such that
\begin{equation}\label{e:ass_power}
    |\Delta \varphi(x)| \leq C|\varphi(x)|^\theta \qquad\text{and}\qquad |D \varphi(x)|^2 \leq C\varphi^{1+\theta}
\end{equation}
for $x\in \Omega$ and $C = C(\delta,\theta)$.
Let $w(x) = |Du(x)|^2$ for $x\in \Omega$, the goal is to derive an equation for $\varphi w$. The equation for $w$ is given by
\begin{equation*}
    -\varepsilon \Delta w + p|D u|^{p-2}D u \cdot D w + 2\lambda w - D f\cdot D u + \varepsilon |D^2u|^2 = 0 \qquad\text{in}\;\Omega.
\end{equation*}
Using that, we can derive an equation for $(\varphi w)$ as follows.
\begin{align*}
    &-\varepsilon \Delta (\varphi w) + p|D u|^{p-2}D u \cdot D (\varphi w) + 2\lambda (\varphi w) + \varepsilon \varphi|D^2u|^2 + 2\varepsilon \frac{D \varphi}{\varphi}\cdot D (\varphi w) \\
    &\qquad\qquad\qquad\qquad = \varphi(D f\cdot D u) + p|D u|^{p-2}(D u\cdot D \varphi)w -\varepsilon w \Delta \varphi + 2\varepsilon \frac{|D \varphi|^2}{\varphi}w
    \qquad\text{in}\;\mathrm{supp}\;\varphi.
\end{align*}
Assume that $\varphi w$ achieves its maximum over $\overline{\Omega}$ at $x_0\in \Omega$ then we can assume that $x_0\in \mathrm{supp}\;\varphi$, since otherwise the maximum of $\varphi w$ over $\overline{\Omega}$ is zero. By the classical maximum principle 
\begin{equation*}
    -\varepsilon \Delta(\varphi w)(x_0)\geq 0 \qquad\text{and}\qquad |D(\varphi w)(x_0)| = 0.
\end{equation*}
Using that in the equation of $\varphi w$ above, we obtain that
\begin{equation*}
    \varepsilon \varphi|D^2u|^2 \leq  \varphi (Df\cdot Du)+ p|Du|^{p-1} |D\varphi|w + \varepsilon w |\Delta\varphi|  + 2\varepsilon  w\frac{|D\varphi|^2}{\varphi},
\end{equation*}
where all terms are evaluated at $x_0$. Using \eqref{e:ass_power} we have
\begin{equation}\label{e:est_for_D^2u}
    \varepsilon \varphi|D^2u|^2 \leq  \varphi |Df|w^{\frac{1}{2}}+ Cp w^{\frac{p-1}{2}+1} \varphi^{\frac{1+\theta}{2}} + C\varepsilon w \varphi^{\theta} + 2C\varepsilon  w\varphi^\theta.
\end{equation}
By Cauchy-Schwartz inquality, we have $n|D^2u|^2\geq (\Delta u)^2$, thus if $n\varepsilon < 1$ then
\begin{equation}\label{e:est_for_D^2u_2}
    \varepsilon |D^2u|^2 \geq \frac{(\varepsilon \Delta u)^2}{n\varepsilon} \geq (\varepsilon \Delta u)^2 = \left(\lambda u + |Du|^p - f\right)^2 \geq |Du|^{2p} - 2C_0|Du|^p \geq \frac{|Du|^{2p}}{2} - 2K_0.
\end{equation}
Using \eqref{e:est_for_D^2u_2} in \eqref{e:est_for_D^2u} we obtain that
\begin{equation*}
    \varphi\left(\frac{1}{2}w^p - 2K_0\right) \leq \varphi |Df|w^{\frac{1}{2}}+ Cp w^{\frac{p-1}{2}+1} \varphi^{\frac{1+\theta}{2}} + 3C\varepsilon w \varphi^{\theta}.
\end{equation*}
Multiply both sides by $\varphi^{p-1}$ we deduce that
\begin{align*}
    (\varphi w)^p \leq 4K_0\varphi^{p-1} + 2\Vert Df\Vert_{L^\infty}\varphi^p w^{\frac{1}{2}} + 2Cp \varphi^{\frac{2p+\theta - 1}{2}}w^{\frac{p+1}{2}} + 6C\varepsilon \varphi^{p+\theta - 1}w.
\end{align*}
Choose $2p+\theta -1 \geq p+1$, i.e., $p+\theta\geq 2$. This is always possible with the requirement $\theta \in (0,1)$, as $1<p <\infty$. We deduce that 
\begin{equation}\label{e:est_for_D^2u_3}
    (\varphi w)^p \leq C\left(1+ (\varphi w)^\frac{1}{2} + (\varphi w)^\frac{p+1}{2} +(\varphi w)\right)
\end{equation}
As a polynomial in $z = (\varphi w)(x_0)$, this implies that $(\varphi w)(x_0)\leq C$ where $C$ depends on coefficients of the right hand side of \eqref{e:est_for_D^2u_3}, which implies our desired gradient bound since $\overline{\Omega}_\delta\subset \mathrm{supp}\;\varphi$.
\end{proof}



\subsection{Well-posedness of large solution for subquaratic case} In this section, with the specific form of the Hamiltonian $H(x,\varrho) = |\varrho|^p - f(x)$ where $1<p\leq 2$ and $f\in \mathrm{C}(\overline{\Omega})\cap W^{1,\infty}(\Omega)$, we show the existence and uniqueness of solutions to \eqref{eq:PDEeps}. 
We note that the assumption of $f$ can be relaxed to $f\in L^\infty(\Omega)$, but for the clarity of the proof we will assume $f\in \mathrm{C}(\overline{\Omega})\cap W^{1,\infty}(\Omega)$.

\begin{thm} If $H(x,\varrho) = |\varrho|^p - f(x)$ where $1<p< 2$ and $f\in \mathrm{C}(\overline{\Omega})\cap W^{1,\infty}(\Omega)$ then there exists a unique solution $u^\varepsilon\in \mathrm{C}^2(\Omega)$ of \eqref{eq:PDEeps} such that
\begin{equation*}
    %\frac{C_\varepsilon-\eta}{d(x)^\alpha}-\frac{M_\eta}{\lambda} \leq u(x)\leq \frac{C_\varepsilon+\eta}{d(x)^\alpha}+\frac{M_\eta}{\lambda} 
    \lim_{d(x)\to 0} u^\varepsilon(x) \,d(x)^\alpha = C_\varepsilon 
\end{equation*}
where
\begin{equation*}
    \displaystyle\alpha = \frac{2-p}{p-1} \qquad\text{and}\qquad C_\varepsilon = \left(\frac{1}{\alpha}(\alpha+1)^\frac{1}{p-1}\right) \varepsilon^{\frac{1}{p-1}}.
\end{equation*}
\end{thm}

\begin{proof} 

\noindent To find a candidate for subsolution and supersolution to \eqref{eq:PDEeps}, we use the \emph{ansatz}
\begin{equation}\label{eq:ansatz}
    u(x) = C_\varepsilon d(x)^{-\alpha}, \qquad x\in \Omega
\end{equation}
as we expect it blows up near the boundary like some thing proportionate to inverse of the distance function, due to the structure of $H(x,\varrho) = |\varrho|^p - f(x)$. Let us plug \eqref{eq:ansatz} into \eqref{eq:PDEeps} we obtain that 
\begin{align*}
    \lambda u(x) &\approx C_\varepsilon d(x)^{-\alpha},\\
    \frac{\partial u}{\partial x_i}(x) &\approx -\alpha C_\varepsilon d(x)^{-(\alpha+1)} \frac{\partial d}{\partial x_i}(x) \qquad\qquad\qquad \Longrightarrow\qquad |Du (x)|^p \approx \alpha^p C_\varepsilon^p d(x)^{-p(\alpha+1)}|D d(x)|^p,\\
    %\frac{\partial^2 u}{\partial x_i^2}(x) &\approx \alpha(\alpha+1)C_0 d(x)^{-(\alpha+2)}\left|\frac{\partial d}{\partial x_i}(x)\right|^2 -\alpha C_0 d(x)^{-(\alpha+1)}\frac{\partial ^2 d}{\partial x_i^2}(x),\\
    \varepsilon\Delta u(x) &\approx \frac{\varepsilon C_\varepsilon\alpha(\alpha+1)}{d(x)^{\alpha+2}}|D d(x)|^2 - \frac{\varepsilon C_\varepsilon\alpha}{d(x)^{\alpha+1}}\Delta d(x).
\end{align*}
As $|D d(x)| = 1$ for $x$ near $\partial\Omega$, we see that as $x\to \partial \Omega$, the highest explosive order terms are
\begin{equation*}
        -\varepsilon C_\varepsilon \alpha(\alpha+1)d^{-(\alpha+2)} + C_\varepsilon^p \alpha^p d^{-(\alpha+1)p}.
\end{equation*}
Setting them to zero, we deduce that
\begin{equation}\label{e:relation}
    \displaystyle\alpha = \frac{2-p}{p-1} \qquad\text{and}\qquad C_\varepsilon = \left(\frac{1}{\alpha}(\alpha+1)^\frac{1}{p-1}\right) \varepsilon^{\frac{1}{p-1}} = \frac{1}{\alpha}(\alpha+1)^{\alpha+1}\varepsilon^{\alpha+1}.
\end{equation}
We note that $\alpha+1 = \frac{1}{p-1}$ for convenience later. Recall that $_1 = \max_{\overline{\Omega}}|\Delta d(x)|$, let us denote
\begin{equation*}
    G = \left[\left(K_1\delta_0+(\alpha+1)\right)^{\alpha+1} - (\alpha+1)^{\alpha+1}\right]\alpha.
\end{equation*}

\begin{lem}\label{lem:subsln} For each $<\delta < \frac{1}{2}\delta_0$, if $\eta\geq G\varepsilon^{\alpha+1}$, we have
\begin{equation*}
    \overline{w}_{\eta,\delta}(x) = \frac{C_\varepsilon+\eta}{(d(x)-\delta)^\alpha} +\frac{M_\varepsilon}{\lambda},\qquad x\in \Omega_\delta, 
\end{equation*}
is a supersolution of \eqref{eq:PDEeps} in $\Omega_\delta$ where
\begin{equation}\label{e:M_eps}
    M_\varepsilon = \max_{\overline{\Omega}} f + 2\left(\frac{2}{\delta_0}\right)^{\alpha+1}K_1(\alpha+1)^{\alpha+1}\varepsilon^{\alpha+2} + \left(\frac{2(\alpha+1)\varepsilon}{\delta_0}\right)^{\alpha+2}\big(2^pK_2^p+2K_2^2\big).
\end{equation}
\end{lem}
\noindent The reason why we state this lemma again instead of just citing \cite{Lasry1989} is because we want to show that the constant $M_\varepsilon$ here can be chosen independent of $\eta$ as long as $\eta \geq G\varepsilon^{\alpha+1}$, thus $\{M_\varepsilon\}_{\varepsilon>0}$ is bounded.
\begin{proof} Recall that $p(\alpha+1) = \alpha+2$, we compute
\begin{align*}
    \mathcal{L}^\varepsilon\left[\overline{w}_{\eta,\delta}\right](x) = \frac{\lambda(C_\varepsilon + \eta)}{(d(x)-\delta)^\alpha} &+ M_\varepsilon + \frac{(C_\varepsilon+\eta)^p \alpha^p}{(d(x)-\delta)^{\alpha+2}}|D d(x)|^p - f(x) \\
    &- \frac{\varepsilon(C_\varepsilon+\eta)\alpha(\alpha+1)}{(d(x)-\delta)^{\alpha+2}}|D d(x)|^2 + \frac{\varepsilon(C_\varepsilon+\eta)\alpha}{(d(x)-\delta)^{\alpha+1}}\Delta d(x).
\end{align*}
Regarding the relation \eqref{e:relation}, we define
\begin{equation*}
    1<\nu = \left(\frac{C_\varepsilon+\eta}{C_\varepsilon}\right) \leq 2.
\end{equation*}
There are two cases to be considered.
\begin{itemize}
    \item In the region where $d(x)\geq \delta_0$ then $d(x)-\delta \geq \frac{1}{2}\delta_0$, therefore 
    \begin{align*}
        \mathcal{L}^\varepsilon\left[\overline{w}_{\eta,\delta}\right](x) = \frac{\lambda(C_\varepsilon + \eta)}{(d(x)-\delta)^\alpha} + M_\varepsilon &+ \frac{\alpha^pC_\varepsilon^p}{(d(x)-\delta)^{\alpha+2}}\left(\nu^{p}|Dd(x)|^p - \nu|Dd(x)|^2\right)\\
        &+\frac{\nu\varepsilon \alpha C_\varepsilon}{(d(x)-\delta)^{\alpha+1}}\Delta d(x) - f(x).
    \end{align*}
Recall that $K_2 = \max_{x\in\overline{\Omega}}|Dd(x)|$ and $1<|\nu|\leq 2$, we have
\begin{align*}
    \frac{\alpha^pC_\varepsilon^p}{(d(x)-\delta)^{\alpha+2}}\left|\nu^{p}|Dd(x)|^p - \nu|Dd(x)|^2\right| &\leq \left(\frac{2(\alpha+1)\varepsilon}{\delta_0}\right)^{\alpha+2}\big(2^pK_2^p+2K_2^2\big).
\end{align*}
%As $|Dd(x)|\leq 1$, $\nu^p|Dd(x)|^p - \nu|Dd(x)|^2 \geq 0$ since $1<p<2$ and $\nu>1$. Finally
\begin{equation*}
    \frac{\nu\varepsilon \alpha C_\varepsilon}{(d(x)-\delta)^{\alpha+1}}|\Delta d(x)| \leq 2\left(\frac{2}{\delta_0}\right)^{\alpha+1}K_1 \alpha\varepsilon C_\varepsilon \leq 2\left(\frac{2}{\delta_0}\right)^{\alpha+1}K_1 (\alpha+1)^{\alpha+1}\varepsilon^{\alpha+2}.
\end{equation*}
 From the definition of $M_\varepsilon$ in \eqref{e:M_eps} we deduce that $\mathcal{L}^\varepsilon\left[\overline{w}_{\eta,\delta}\right]\geq 0$ in this region.
    \item In the region where $\delta < d(x)\leq \delta_0$, we have $|Dd(x)|=1$, thus
    \begin{align*}
         \mathcal{L}^\varepsilon\left[\overline{w}_{\eta,\delta}\right](x) &= \frac{\lambda(C_\varepsilon + \eta)}{(d(x)-\delta)^\alpha} + M - f(x)\\
         & + \frac{\alpha^p C_\varepsilon^p}{(d(x)-\delta)^{\alpha+2}}\nu\left(\nu^{p-1} - 1 - \frac{ (d(x)-\delta)\Delta d(x)}{(\alpha+1)}\right).
    \end{align*}
    We note that as $0<d(x)\leq \delta_0$, we have
    \begin{equation*}
        \left|\frac{(d(x)-\delta)\Delta  d(x)}{(\alpha+1)}\right| \leq \frac{_1\delta_0}{\alpha+1}.
    \end{equation*}
    Recall that $\nu = \left(1+\frac{\eta}{C_\varepsilon}\right)$, we want to choose $\eta$ such that
    \begin{equation*}
        \left(1+\frac{\eta}{C_\varepsilon}\right)^{p-1} - 1 \geq \frac{K_1\delta_0}{\alpha+1} \qquad\Longrightarrow\qquad \eta \geq C_\varepsilon\left[\left(1+\frac{K_1\delta_0}{\alpha+1}\right)^{\alpha+1}-1\right] = G\varepsilon^{\alpha+1}
    \end{equation*}
    where we use $\frac{1}{p-1} = \alpha+1$ again. This will ensure that $\mathcal{L}^\varepsilon\left[\overline{w}_{\eta,\delta}\right](x) \geq 0$ in this region.
\end{itemize}
\end{proof}

\begin{lem}\label{lem:supersln} For each $\eta\geq G\varepsilon^{\alpha+1}$ there exists $M_\eta > 0$ such that 
\begin{equation*}
    \underline{w}_{\eta, \delta}(x) = \frac{C_\varepsilon-\eta}{(d(x)+\delta)^\alpha} -\frac{M_\varepsilon}{\lambda}, \qquad x\in \Omega^\delta 
\end{equation*}
is a subsolution of \eqref{eq:PDEeps} in $\Omega^\delta$.
\end{lem}

\begin{proof} The proof for this Lemma should be the same with Lemma \ref{lem:subsln}.
\end{proof}

\noindent We divide the rest of the proof into 3 steps. We first construct a minimal solution, then a maximal solution to \eqref{eq:PDEeps}, and finally show that they are equal to conclude the existence and uniqueness of solution to \eqref{eq:PDEeps}.

\begin{prop}\label{pro:minimalsol} There exists a minimal solution $\underline{u}\in \mathrm{C}^2(\Omega)$ of \eqref{eq:PDEeps} such that $v\geq \underline{u}$ for any other solution $v\in \mathrm{C}^2(\Omega)$ solving \eqref{eq:PDEeps}.
\end{prop}
\begin{proof} Let $w_{\eta,\delta}\in \mathrm{C}^2(\Omega)$ solves
    \begin{equation}\label{e:w_def}
    \begin{cases}
        \mathcal{L}\left[w_{\eta,\delta}\right] = 0 &\qquad\text{in}\;\Omega,\\
        \qquad w_{\eta,\delta} = \underline{w}_{\eta,\delta} &\qquad\text{on}\;\partial\Omega.
    \end{cases}
    \end{equation}
    \begin{itemize}
        \item Fix $\eta>0$ (and $\eta\geq G\varepsilon^{\alpha+1}$ in view of Lemmas \ref{lem:subsln} and \ref{lem:supersln}), as $\delta\to 0$ the value of $\underline{w}_{\eta,\delta}$ blows up on the boundary, therefore by the standard comparison principle for second-order elliptic equation with Dirichlet boundary we have $\delta_1 \leq  \delta_2$ implies $w_{\eta,\delta_1}\geq  w_{\eta,\delta_2}$ on $\overline{\Omega}$. 
        \item For $\delta'>0$, since $\underline{w}_{\eta,\delta'}$ is a subsolution in $\overline{\Omega}$ with finite boundary, we obtain that
            \begin{equation}\label{e:cp_delta1}
                0<\delta \leq \delta'\qquad\Longrightarrow\qquad \underline{w}_{\eta,\delta'} \leq w_{\eta_,\delta'}\leq w_{\eta,\delta} \qquad\text{on}\;\overline{\Omega}.
            \end{equation}
        \item Similarly, since $\overline{w}_{\eta,\delta'}$ is a supersolution on $\Omega_{\delta'}$ with infinity value on the boundary $\partial\Omega_{\delta'}$, by comparison principle
            \begin{equation}\label{e:cp_delta2}
                w_{\eta,\delta} \leq \overline{w}_{\eta, \delta'} \qquad\text{in}\;\Omega_{\delta'} \qquad\Longrightarrow\qquad w_{\eta,\delta} \leq \overline{w}_{\eta,0} \qquad\text{in}\;\Omega.
            \end{equation}
    \end{itemize}
    \noindent From \eqref{e:cp_delta1} and \eqref{e:cp_delta2} we have
    \begin{equation}\label{e:cp_delta3}
        0<\delta \leq \delta'\qquad\Longrightarrow\qquad \underline{w}_{\eta,\delta'} \leq w_{\eta_,\delta'}\leq w_{\eta,\delta} \leq \overline{w}_{\eta,0} \qquad\text{in}\;\Omega.
    \end{equation}
    Thus $\{w_{\eta,\delta}\}_{\delta>0}$ is locally bounded in $L^{\infty}_{\mathrm{loc}}(\Omega)$ ($\{w_{\eta,\delta}\}_{\delta>0}$ is uniformly bounded from below), thus using the local gradient estimate for $w_{\eta,\delta}$ solving \eqref{e:w_def} we deduce that $\{w_{\eta,\delta}\}_{\delta>0}$ is locally bounded in $W^{1,\infty}_{\mathrm{loc}}(\Omega)$. Plug it back into the defining equation \eqref{e:w_def} we deduce that $\{w_{\eta,\delta}\}_{\delta>0}$ is locally bounded in $W^{2,r}_{\mathrm{loc}}(\Omega)$ for all $r<\infty$.
    
    \noindent Local boundedness of $\{u_{\eta,\delta}\}_{\delta>0}$ in $W^{2,r}_{\mathrm{loc}}(\Omega)$ implies weak$^*$ compactness, that is there exists a function $u\in W^{2,r}(\Omega)$ such that (via subsequence and monotonicity)
    \begin{equation*}
        w_{\eta,\delta} \rup u \qquad\text{weakly in}\;W^{2,r}_{\mathrm{loc}}(\Omega),\qquad \text{and}\qquad
        w_{\eta,\delta} \to u \qquad\text{strongly in}\;W^{1,r}_{\mathrm{loc}}(\Omega).
    \end{equation*}
    In particular, $w_{\eta,\delta}\to u$ in $\mathrm{C}^1_{\mathrm{loc}}(\Omega)$ thanks to Sobolev compact embedding. Let us rewrite the equation $\mathcal{L}^\varepsilon\left[u_{\eta,\delta}\right] = 0$ as $\varepsilon\Delta w_{\eta,\delta}(x) = F[w_{\eta,\delta}](x)$ in $U$ for $U\subset\subset \Omega$ where
    \begin{equation*}
        F[w_{\eta,\delta}](x) =  \lambda w_{\eta,\delta}(x) + H(x,Dw_{\eta,\delta}(x)).
    \end{equation*}
    Since $u_{\eta,\delta}\to u$ in $\mathrm{C}^1(U)$ as $\delta\to 0$, we have $F[w_{\eta,\delta}](x) \to F(x)$ uniformly in $U$ where 
    \begin{equation*}
        F(x) = \lambda u(x) + H(x,Du(x)).
    \end{equation*}
    In the limit as $\delta\to 0$ we obtain that $u\in L^2(U)$ is a weak solution of $\varepsilon\Delta u = F$ in $U$ where $F$ is continuous, thus $u\in \mathrm{C}^2(\Omega)$ and by stability $u$ solves $\mathcal{L}^\varepsilon[u] = 0$ in $\Omega$. From \eqref{e:cp_delta3} we also have
    \begin{equation*}
        \underline{w}_{\eta,0} \leq u \leq \overline{w}_{\eta,0} \qquad\text{in}\;\Omega.
    \end{equation*}
    It is clear that $u(x)\to \infty$ as $\mathrm{dist}(x,\partial\Omega)\to 0$ with the precise rate like \eqref{eq:ansatz}. We note that at this point, by construction, $u$ may depend on $\eta$. We show that $u$ is the maximal solution of $\mathcal{L}^\varepsilon[u] = 0$ in $\Omega$ such that $u = +\infty$ on $\partial\Omega$, thus consequently showing that $u$ is independent of $\eta$.
    
    \noindent Let $v\in W^{2,r}(\Omega)$ for all $r<\infty$ and $v$ solves \eqref{eq:PDEeps}. Fix $\delta>0$ then since $v(x)\to \infty$ as $x\to \partial\Omega$ while $w_{\eta,\delta}$ remains bounded on $\partial \Omega$, comparison principle yields
    \begin{equation*}
        v\geq w_{\eta,\delta} \qquad\text{in}\Omega.
    \end{equation*}
    Let $\delta\to 0$ we deduce that $v\geq u$ on $\Omega$. This concludes that $u$ is the minimal solution in $W^{2,r}(\Omega)(\forall\,r<\infty)$ and thus $u$ is independent of $\eta>0$. 
\end{proof}



\begin{prop} There exists a maximal solution $\overline{u}\in \mathrm{C}^2(\Omega)$ of \eqref{eq:PDEeps} such that $v\leq \overline{u}$ for any other solution $v\in \mathrm{C}^2(\Omega)$ solving \eqref{eq:PDEeps}.
\end{prop}

\begin{proof} For each $\delta>0$, let us denote $u_\delta\in \mathrm{C}^2(\Omega_\delta)$ be the minimal solution to $\mathcal{L}[u_\delta] = 0$ in $\Omega$ and $u_\delta = +\infty$ on $\partial\Omega_\delta$ according to Proposition \ref{pro:minimalsol}. By comparison principle, for every $\eta>0$ there holds
\begin{equation*}
    \underline{w}_{\eta,\delta} \leq u_\delta \leq \overline{w}_{\eta,\delta} \qquad\text{in}\;\Omega_\delta,
\end{equation*}
and
\begin{equation*}
    0<\delta<\delta' \qquad \Longrightarrow\qquad u_\delta \leq u_\delta' \qquad\text{in}\;\Omega_{\delta'}.
\end{equation*}
We have the local boundedness of $\{u_\delta\}_{\delta>0}$ in $W^{2,r}(\Omega)$ as well, thus together with monotonicity there exists $u\in W^{2,r}(\Omega)$ for all $r<\infty$ such that $u_\delta\to u$ strongly in $\rmC^1_{\mathrm{loc}}(\Omega)$, therefore using the equation $\mathcal{L}[u_\delta] = 0$ in $\Omega_\delta$ and the regularity of Laplace equation we deduce that $u\in \mathrm{C}^2(\Omega)$ solving \eqref{eq:PDEeps} and 
\begin{equation*}
    \underline{w}_{\eta,0} \leq u\leq \overline{w}_{\eta,0} \qquad\text{in}\;\Omega
\end{equation*}
for all $\eta>0$. From the construction, as $u_\delta$ is independent of $\eta$, it is clear that $u$ is also independent of $\eta$. We now show that $u$ is the maximal solution of \eqref{eq:PDEeps}. Let $v\in\rmC^2(\Omega)$ solves \eqref{eq:PDEeps}, then clearly $v\leq u_\delta$ on $\Omega_\delta$ and therefore as $\delta \to 0$ we have $v\leq u$.
\end{proof}
\noindent In conclusion we have found a minimal solution $\underline{u}$ and a maximal solution $\overline{u}$ in $\rmC^2(\Omega)$ such that
\begin{equation}\label{e:chain}
    \underline{w}_{\eta,0} \leq \underline{u}\leq \overline{u}\leq \overline{w}_{\eta,0} \qquad\text{in}\;\Omega
\end{equation}
for any $\eta>0$. This extra parameter $\eta$ now enables us to show that $\overline{u} = \underline{u}$ in $\Omega$. The key ingredient here is the convexity of $\varrho\mapsto H(x,\varrho)$.

\begin{prop}[Uniqueness] We have $\overline{u}\equiv \underline{u}$ in $\Omega$ and therefore solution to \eqref{eq:PDEeps} in $\mathrm{C}^2(\Omega)$ is unique.
\end{prop}

\begin{proof} Let $\theta\in (0,1)$, we cook up a subsolution by convex combination $w_\theta = \theta \overline{u} + (1-\theta)\lambda^{-1}\left(\inf_{\Omega} f\right)$, which if we can use comparison principle then
\begin{equation*}
    w_\theta = \theta \overline{u} + (1-\theta)\lambda^{-1}\left(\inf_{\Omega} f\right) \leq \underline{u} \qquad\text{in}\;\Omega.
\end{equation*}
If that is the case, let $\theta\to 1$ we conclude that $\overline{u} \leq \underline{u}$. There is a problem here, as they are both explosive solutions, to use comparison principle we need to show that $w_\theta \leq \underline{u}$ in a neighborhood of $\partial\Omega$. From \eqref{e:chain} we see that
\begin{equation*}
    1\leq \frac{\overline{u}(x)}{\underline{u}(x)} \leq \frac{\overline{w}_{\eta,0}(x)}{\underline{w}_{\eta,0}(x)} = \frac{(C_0+\eta)+\lambda^{-1}C_\eta d(x)^\alpha}{(C_0-\eta)-\lambda^{-1}C_\eta d(x)^\alpha} \qquad\text{for}\;x\in \Omega
\end{equation*}
and therefore
\begin{equation*}
   1\leq  \lim_{d(x)\to 0} \left(\frac{\overline{u}(x)}{\underline{u}(x)}\right) \leq \frac{C_0+\eta}{C_0-\eta} \qquad\Longrightarrow\qquad  \lim_{d(x)\to 0} \left(\frac{\overline{u}(x)}{\underline{u}(x)}\right) = 1
\end{equation*}
since $\eta>0$ is chosen arbitrary. This means for any $\varsigma\in(0,1)$ we can find $\delta(\varsigma)>0$ small such that on $\Omega\backslash \Omega_\delta$ one has
\begin{equation*}
\frac{\overline{u}(x)}{\underline{u}(x)}\leq (1+\varsigma)     \qquad\Longrightarrow\qquad \frac{1}{1+\varsigma} \overline{u}(x) \leq \underline{u}(x) \qquad\text{in}\; \Omega\backslash \Omega_\delta
\end{equation*}
For given $\theta\in (0,1)$, we can always choose $\varsigma$ small enough such that $(1+\varsigma)^{-1} > \theta$ which renders $\underline{u}(x) \geq \theta \overline{u}(x) + (1-\theta)\lambda^{-1}\left(\inf_\Omega f\right)$ for $0< d(x) < \delta' < \delta$.
\end{proof}
\noindent A final remark is that, we can also repeat the proof for $p=2$.
\end{proof}
\subsection{Convergence result} We show the convergence (qualitatively) of \eqref{eq:PDEeps} to \eqref{eq:PDE0}. We first state the following Lemma (\cite{Capuzzo-Dolcetta1990}), which characterizes the state-constraint of the first-order equation
\begin{equation}\label{S_0}
 \lambda u(x) + H(x,Du(x)) = 0\;\qquad\text{in}\;\Omega. \tag{$S_0$}
\end{equation}

\begin{lem}\label{lem:max} Let $u\in \rmC(\overline{\Omega})$ be a viscosity subsolution of \eqref{S_0} such that, for all viscosity subsolution $v\in \rmC(\overline{\Omega})$ of \eqref{S_0} one has $v\leq u$ in $\overline{\Omega}$, then $u$ is a viscosity supersolution of \eqref{S_0} on $\overline{\Omega}$.
\end{lem}
\noindent Lemma \ref{lem:max} is a variation of Perron's method. We give a proof in Appendix for the sake of completeness. Let $u^\varepsilon\in \mathrm{C}^2(\Omega)$ be a solution to \eqref{eq:PDEeps}, we claim that $\{\lambda u^\varepsilon\}_{\varepsilon>0}$ is uniformly bounded from below by a constant independent of $\varepsilon$ and $\lambda$. We have
\begin{equation*}
    u^\varepsilon(x) = \lim_{m\to \infty} u^{\varepsilon}_m(x), \qquad x\in \Omega,
\end{equation*}
 where $u^{\varepsilon,m}\in \mathrm{C}^2(\Omega)\cap \rmC(\overline{\Omega})$ solves the Drichlet problem
\begin{equation}\label{e:uepsm}
    \begin{cases}
    \lambda u(x) + H(x,Du(x)) - \varepsilon \Delta u(x) = 0 &\qquad
    \text{in}\;\Omega, \vspace{0cm}\\
    \;\;\quad\quad\qquad\qquad\qquad\qquad u(x) = m &\qquad
    \text{on}\;\partial\Omega.
    \end{cases} \tag{PDE$_{\varepsilon,m}$}
\end{equation}
If we assume $\mathrm{(H2)}$ then we can take $C_2 = \Vert f\Vert_{L^\infty(\Omega)}$ and take $\varphi(x) \equiv -\lambda^{-1}C_2$ for $x\in \overline{\Omega}$ as a subsolution to \eqref{e:uepsm}, hence by comparison principle for \eqref{e:uepsm} we have $u^{\varepsilon}_m(x)\geq -\lambda^{-1}C_2$ for all $x\in \overline{\Omega}$, thus as $m\to \infty$ we obtain $u^\varepsilon(x) \geq -\lambda^{-1}C_2$ for all $x\in \Omega$.

The following Theorem says that the large solution $u^\varepsilon$ converges to $u^0$ locally uniformly on $\Omega$ as $\varepsilon\to 0$. We present a simple proof here for the reader's convenience, see also \cite[Theorem VII.3]{Capuzzo-Dolcetta1990}.
\begin{thm}[Vanishing viscosity - Qualitative result]\label{thm:qual} Assume $\mathrm{(A1)}$. Let $u^\varepsilon$ be the solution to \eqref{eq:PDEeps}, then there exists $u^0 \in \mathrm{C}(\overline{\Omega})$ such that $u^\varepsilon \rightarrow u^0$ locally uniformly in $\Omega$ as $\varepsilon\rightarrow 0$, $u^0$ solves \eqref{eq:PDE0} and $u^0 \leq u^\varepsilon$ in $\Omega$.
\end{thm}

\begin{proof}[Proof of Theorem \ref{thm:qual}] By the priori estimate
\begin{equation*}
    |u^\varepsilon(x)| + |Du^\varepsilon(x)| \leq C_\delta \qquad\text{for}\;x\in \overline{\Omega}_\delta
\end{equation*}
we deduce from the Arzel\'a--Ascoli theorem that there exists a subsequence $\varepsilon_j\to 0$ and a function $u^0\in \rmC(\Omega)$ such that $u^{\varepsilon_j}\to u^0$ locally uniformly in $\Omega$. By the stability of viscosity solution we easily deduce that 
\begin{equation}\label{eq:u0int}
   \lambda u^0(x) + H(x,Du^0(x)) = 0 \qquad\text{in}\;\Omega.
\end{equation}
Since $u^\varepsilon(x)\geq -C_2$ for all $x\in \Omega$ we also have $u^0(x)\geq -C_2$ for all $x\in \Omega$, thus together with \eqref{eq:u0int} we obtain $H(x,\xi) \leq C_2$ for all $\xi\in D^+u^0(x)$ and $x\in \Omega$. The coercivity $\mathrm{(H4)}$ implies that there exists $K>0$ such that 
\begin{equation*}
    |u^0(x) - u^0(y)| \leq K \qquad\text{for all}\;x,y\in \Omega.
\end{equation*}
Thus we can extend $u^0$ uniquely to $u^0\in \rmC(\overline{\Omega})$. We will use Lemma \ref{lem:max} to show that $u^0$ is a supersolution of \eqref{S_0} on $\overline{\Omega}$. It suffices to to show that $u^0\geq w$ on $\overline{\Omega}$ where $w\in \rmC(\overline{\Omega})$ is the unique solution to \eqref{eq:PDE0}.

For $\delta>0$, let $\Omega_\delta = \{x\in \Omega: \mathrm{dist}(x,\Omega) < \delta\}$ and $v_\delta\in\rmC(\overline{\Omega}_\delta)$ be the state-constraint viscosity subsolution to the problem $\lambda u(x) + H(x,Du(x)) = 0$ in $\Omega_\delta$. As $v_\delta\rightarrow w$ locally uniformly as $\delta\rightarrow 0^+$ (see \cite{kim_state-constraint_2020}) and $w$ is bounded, therefore $\{v_\delta\}_{\delta>0}$ is uniformly bounded. Let $v^\varepsilon_\delta\in \rmC^2(\Omega_\delta)\cap \rmC(\overline{\Omega}_\delta)$ be the unique solution to the Dirichlet problem
\begin{equation}\label{eq:vv_eps}
\begin{cases}
    \lambda v_\delta^\varepsilon(x) + |Dv_\delta^\varepsilon(x)|^p - f(x) = \varepsilon \Delta v_\delta^\varepsilon(x) &\qquad\text{in}\;\Omega_\delta,\\
    \;\;\;\,\quad\qquad\qquad\qquad\qquad v_\delta^\varepsilon = v_\delta &\qquad \text{on}\;\partial\Omega_\delta.
\end{cases}
\end{equation}
It is well-known that $v^\varepsilon_\delta\to v_\delta$ uniformly on $\overline{\Omega}_\delta$ as $\varepsilon\to 0$.

For all $\delta$ small enough $v_\delta\leq u^\varepsilon$ on $\partial \Omega_\delta$, thus by maximum principle $v^\varepsilon_\delta \leq u^\varepsilon$ on $\overline{\Omega}_\delta$. Let $\varepsilon\to 0$ we have $v_\delta \leq u^0$ on $\overline{\Omega}_\delta$.
Let $\delta\rightarrow 0$ we obtain $w\leq u^0$ in $\Omega$, which implies $w\leq u^0$ on $\overline{\Omega}$ since both $w,u^0$ belong to $\rmC(\overline{\Omega})$.
\end{proof}

\subsection{Rate of convergence for first-order equation on nested domain - revisited}
For $\lambda>0$, let $u\in \rmC(\overline{\Omega})$ and $u_\delta\in \rmC(\overline{\Omega}_\delta)$, respectively, state-constraint solutions to 
\begin{equation*}
    \begin{cases}
    \lambda u(x)+H(x,Du(x)) \leq 0 \quad\text{in}\;\Omega,\\
    \lambda u(x)+H(x,Du(x)) \geq 0 \quad\text{on}\;\overline{\Omega},
    \end{cases}\qquad\text{and}\qquad 
    \begin{cases}
    \lambda u_\delta(x)+H(x,Du_\delta(x)) \leq 0 \quad\text{in}\;\Omega_\delta,\\
    \lambda u_\delta(x)+H(x,Du_\delta(x)) \geq 0 \quad\text{on}\;\overline{\Omega}_\delta.
    \end{cases}
\end{equation*} 
It is well-known that $0\leq u_\delta(x) - u(x) \leq C\delta$ for $x\in\overline{\Omega}_\delta$ and this rate is optimal. This can be proved easily by comparison principle when the domain have a scaling structure, i.e., $\Omega_\delta = (1-\delta)\Omega$ (see \cite{kim_state-constraint_2020}). In the general case when the scaling structure is not available but $\partial\Omega$ is smooth enough, for example $\partial\Omega$ is of class $\mathrm{C}^2$, one can construct a $\rmC^2$ diffeomorphism $T:\overline{\Omega}_\delta\to \overline{\Omega}$ that maps $\partial\Omega_\delta$ to $\partial\Omega$ and do scaling with 
\begin{equation*}
 \tilde{u}_\delta(x) = u_\delta\left(T^{-1}(x)\right)   
\end{equation*}
defined on $\overline{\Omega}$ (see \cite{Capuzzo-Dolcetta1990}). We present here a simple proof using the doubling variables technique.


\begin{thm}\label{thm:conv_general} Let $\Omega$ be an open, bounded and connected subset $\mathbb{R}^n$ with $\mathrm{C}^2$ boundary. Assume $\mathrm{(H1)}-\mathrm{(H4)}$. 
Then there exists a constant $C$ such that
\begin{equation*}
    0\leq u_\delta(x) - u(x) \leq C\delta \qquad\text{for}\; x\in \overline{\Omega}.
\end{equation*}
\end{thm}
\begin{proof} We use $d(\cdot)$ to denote the extension of the distance function as in \eqref{e:distance_def}. Denote by $C_0$ the constant in the priori estimate
\begin{equation*}
    |u_\delta(x)| + |Du_\delta(x)|\leq C_0  \qquad\text{for}\;x\in \overline{\Omega}_\delta.
\end{equation*}
We note that this estimate with the same constant $C_0$ holds for $u\in \rmC(\overline{\Omega})$ as well. We will consider $\delta\in (0,1)$ small so that $0<\delta < \delta_1$ where 
\begin{equation*}
\delta_1 = \min\left\lbrace \delta_0,\frac{\mathrm{diam}(\Omega)\varepsilon_0}{2(4\tilde{C}_0+1)}\right\rbrace.    
\end{equation*}
Without loss of generality, let us assume $x_0\in \Omega$ and $d(x_0)\geq \mathrm{diam}(\Omega)\varepsilon_0\geq \delta$ for some $\varepsilon_0\in (0,1)$. We consider the auxiliary functional
\begin{equation*}
    \Phi^{\theta}(x,y) = u_\delta(x) - u(y) - \frac{2\tilde{C}_0\left|x-y\right|^2}{\theta^\beta} - \frac{C_3\theta^\beta}{d(y)}, \qquad(x,y)\in \overline{\Omega}_\delta\times \overline{\Omega}
\end{equation*}
where $C_3=2\left(4\tilde{C}_0+1\right)$ for some $\beta < 1$. Assume $\Phi^\delta(x,y)$ has a maximum over $\overline{\Omega}_\delta\times \overline{\Omega}$ at $(x_\theta,y_\theta)\in\overline{\Omega}_\delta\times \overline{\Omega}$.
\begin{itemize}
    \item $\Phi^\delta(x_\theta,y_\theta) \geq \Phi^\delta(x_0,x_0)$, which gives us
    \begin{align*}
        u_\delta(x_\theta) - u(y_\theta) - \frac{2\tilde{C}_0|x_\theta - y_\theta|^2}{\theta^\beta} - \frac{C_3\theta^\beta}{d(y_\theta)} \geq u_\delta(x_0) - u(x_0) - \frac{C_3\delta^\beta}{d(x_0)}. 
    \end{align*}
    Therefore, as $C_3 = 2(4\tilde{C}_0+1)$
    \begin{align}\label{e:d(y)}
        \frac{C_3\theta^\beta}{d(y_\theta)} \leq 4\tilde{C}_0 + \frac{C_3 \theta^\beta}{d(x_0)}  \leq 4\tilde{C}_0 + 1 \qquad\Longrightarrow\qquad d(y_\delta) \geq 2\theta^\beta \geq 2\delta
    \end{align}
    since $\beta < 1$.
    \item Since $d(y_\theta)\geq 2\delta$, we have $y_\theta\in \Omega_\delta$ and thus $\Phi^\theta(x_\theta,y_\theta) \geq \Phi^\theta(y_\theta,y_\theta)$, which gives us
    \begin{align*}
        u_\delta(x_\theta) - u(y_\theta) - \frac{2\tilde{C}_0|x_\theta - y_\theta|^2}{\theta^\beta} - \frac{C_3\theta^\beta}{d(y_\theta)} \geq u_\theta(y_\theta) - u(y_\theta) - \frac{C_3\theta^\beta}{d(y_\theta)}. 
    \end{align*}
    I.e.,
    \begin{align*}
        u_\delta(x_\theta)  - \frac{2\tilde{C}_0|x_\theta- y_\theta|^2}{\theta^\beta} \geq u_\delta(y_\theta) 
    \end{align*}
    and thus
    \begin{equation*}
        \frac{2\tilde{C}_0|x_\theta-y_\theta|^2}{\theta^\beta} \leq u_\delta(x_\theta) - u_\delta(y_\theta) \leq \tilde{C}_0|x_\theta-y_\theta|
    \end{equation*}
    and therefore
    \begin{equation}\label{e:x-y}
        |x_\theta-y_\theta|\leq \frac{\theta^\beta}{2}
    \end{equation}
    \item From \eqref{e:d(y)} and \eqref{e:x-y} we obtain that, if $z\in \partial\Omega$ then
    \begin{align*}
        |x_\delta - z| &= |(x_\delta - y_\delta) - (z - y_\delta)| \\
        &\geq |z-y_\delta| - |x_\delta - y_\delta| \geq d(y_\delta) - |x_\delta - y_\delta| \geq 2\delta - \frac{\delta}{2} = \frac{3\delta}{2}.
    \end{align*}
    Therefore
    \begin{equation*}
        d(x_\delta) = \inf_{z\in \partial\Omega} |x_\delta - z|  \geq \frac{3\delta}{2}
    \end{equation*}
    and thus $x_\delta\in \Omega_\delta$.
    \item $x\mapsto \Phi^\delta(x,y_\delta)$ has a maximum at $x_\delta\in \Omega_\delta$, thus
    \begin{equation*}
        \lambda u_\delta(x_\delta) + H\left(x_\delta, \frac{4\tilde{C}_0(x_\delta-y_\delta)}{\delta}\right) \leq 0.
    \end{equation*}
    \item $y\mapsto \Phi^\delta(x_\delta,y)$ has a maximum at $y_\delta\in \overline{\Omega}$, thus
    \begin{equation*}
        \lambda u(y_\delta) + H\left(y_\delta,\frac{4\tilde{C}_0(x_\delta-y_\delta)}{\delta} + C_3\delta^\beta\frac{Dd(y_\delta)}{d(y_\delta)^2} \right) \geq 0.
    \end{equation*}
\end{itemize}
\end{proof}


\section{Rate of convergence via Doubling variables - a toy case}
\noindent Let $\Omega = B(0,1)$. Let $\beta,\sigma,\delta \in (0,1)$ to be chosen later, let us define
\begin{align*}
    \Phi^{\sigma}(x,y) =  u^\varepsilon(x) - u_\delta(y) - \frac{L_0|x-y|^2}{\sigma}- \frac{C_\varepsilon}{d(x)^{\alpha+\beta}}, \qquad (x,y)\in \overline{\Omega}\times\overline{\Omega}_\delta
\end{align*}
where $L_0$ is the Lipschitz constant of $u^0$ and $u_\delta\in \mathrm{C}(\overline{\Omega}_\delta)$ is the state-constraint solution to
\begin{equation*}
    \begin{cases}  
    \lambda u_\delta(x) + H(x,Du_\delta(x)) \leq 0 \qquad\text{in}\; \Omega_\delta\\
    \lambda u_\delta(x) + H(x,Du_\delta(x)) \geq 0 \qquad\text{on}\; \overline{\Omega}_\delta.
    \end{cases}
\end{equation*}
As we are working with the ball, note that $\Omega_\delta = (1-\delta)\Omega$. Let $\mathfrak{F}$ be the Lipschitz constant of $f$.
\paragraph{\textcolor{blue}{\textbf{Step 1.}}} Since $u^\varepsilon (x)d(x)^\alpha \to C_\varepsilon$ as $d(x)\to 0$, we see that $\Phi^\sigma(x,y)\to -\infty$ as $d(x)\to 0$, therefore for a fixed $\varepsilon>0$, there is $(x_{\sigma},y_\sigma)\in \Omega\times\overline{\Omega}_\delta$ such that 
\begin{equation*}
    \max_{\overline{\Omega}\times \overline{\Omega}_\delta} \Phi^\sigma = \Phi^\sigma(x_\sigma,y_\sigma).
\end{equation*}
\paragraph{\textcolor{blue}{\textbf{Step 2.}}} $\Phi^\sigma(x_\sigma,y_\sigma) \geq \Phi^\sigma(x_\sigma,x_\sigma)$ gives us that
    \begin{equation}\label{e:est_sigma2}
        \mathfrak{C}\frac{|x_\sigma-y_\sigma|^2}{\sigma} \leq u_\delta(x_\sigma) - u_\delta(y_\sigma) \leq \mathfrak{C}|x_\sigma-y_\sigma| \qquad\Longrightarrow\qquad |x_\sigma -y _\sigma|\leq \sigma.
    \end{equation}
    This gives us that
    \begin{equation}\label{e:est_sigma3}
        |x_\sigma|\leq |y_\sigma|+\sigma \qquad\Longrightarrow\qquad d(x_\sigma) \geq d(y_\sigma) - \sigma\geq \delta-\sigma.
    \end{equation}
Let 
\begin{equation*}
   \fbox{$\displaystyle \delta = 2\sigma$.}
\end{equation*}
then 
\begin{equation*}
    \fbox{$d(x_\sigma) \geq \sigma$.}
\end{equation*}
\paragraph{\textcolor{blue}{\textbf{Step 3.}}} $x\mapsto \Phi^\sigma(x,y_\sigma)$ has a maximum at $x_\sigma\in \Omega$, thus 
\begin{align*}
    &\lambda u^\varepsilon(x_\sigma) + \left|\frac{2\mathfrak{C}(x_\sigma-y_\sigma)}{\sigma} - \frac{C_\varepsilon(\alpha+\beta)}{d(x_\sigma)^{\alpha+\beta+1}}D d(x_\sigma )\right|^p - f(x_\sigma)\\
    &\qquad\qquad\qquad -\varepsilon\left(\frac{2n}{\sigma} + \frac{C_\varepsilon(\alpha+\beta)(\alpha+\beta+1)|D d(x_\sigma)|^2}{d(x_\sigma)^{\alpha+\beta+2}}-\frac{C_\varepsilon(\alpha+\beta)}{d(x_\sigma)^{\alpha+\beta+1}}\Delta d(x_\sigma)\right)  \leq 0.
\end{align*}
\paragraph{\textcolor{blue}{\textbf{Step 4.}}} $y\mapsto \Phi^\sigma(x_\sigma,y)$ has a maximum at $y_\sigma\in \overline{\Omega}_\delta$, thus 
\begin{equation*}
    \lambda u_\delta(y_\sigma) + \left|\frac{2\mathfrak{C}(x_\sigma-y_\sigma)}{\sigma}\right|^p - f(y_\sigma) \geq 0
\end{equation*}
\paragraph{\textcolor{blue}{\textbf{Step 5.}}} Gradient estimate, let
\begin{equation*}
    \xi_\sigma = \frac{2\mathfrak{C}(x_\sigma-y_\sigma)}{\sigma} \qquad\text{and}\qquad \zeta_\sigma = - \frac{C_\varepsilon(\alpha+\beta)}{d(x_\sigma)^{\alpha+\beta+1}}D d(x_\sigma)
\end{equation*}
then $|\xi_\sigma|\leq 2\mathfrak{C}$ already and furthermore
\begin{equation*}
   \xi_\sigma+\zeta_\sigma \in D^-u^\varepsilon(x_\sigma),
\end{equation*}
which, by the local gradient estimate, as $x_\sigma\in \Omega_{\sigma}$, this is bounded in terms of $\sigma$ and will blow up as $\sigma\to 0$. Nevertheless, we can do better as following.
\begin{equation*}
 |\zeta_\sigma|=   \left|\frac{C_\varepsilon(\alpha+\beta)}{d(x_\sigma)^{\alpha+\beta+1}}D d(x_\sigma )\right| \leq \frac{C_\varepsilon(\alpha+\beta)}{\sigma^{\alpha+\beta+1}}\leq \frac{\alpha+\beta}{\alpha} (\alpha+1)^\frac{1}{p-1}\frac{\varepsilon^\frac{1}{p-1}}{\sigma^{\alpha+\beta+1}}.
\end{equation*}
Thus by choosing $\sigma = \varepsilon^\gamma$ appropriately, we can make this tends to zero as $\varepsilon \to 0$. Indeed, we have
\begin{equation*}
    |\zeta_\sigma| \leq \frac{(\alpha+1)^\frac{1}{p-1}}{\alpha} \varepsilon^{\frac{1}{p-1} - \gamma(\alpha+\beta+1)} = \frac{\alpha+\beta}{\alpha}(\alpha+1)^{\alpha+1}\varepsilon^{\alpha+1 - \gamma(\alpha+1+\beta)},
\end{equation*}
where we made use of the fact that $\alpha+1 = \frac{1}{p-1}$. We see that the first condition we want to impose is
\begin{equation}\label{e:condition_gamma_1}
    \fbox{\qquad\qquad\qquad$\displaystyle 0 < \gamma < \frac{\alpha+1}{\alpha+1+\beta}$\qquad\qquad\qquad.}
\end{equation}
As long as \eqref{e:condition_gamma_1} holds then
\begin{equation}\label{e:bddp_sigmaq_sigma}
    |\zeta_\sigma|\leq \mathfrak{C}_\alpha \qquad\text{where}\qquad \mathfrak{C}_\alpha = \frac{\alpha+\beta}{\alpha}(\alpha+1)^{\alpha+1}.
\end{equation}
\paragraph{\textcolor{blue}{\textbf{Step 6.}}} Recall $|D d(x_\sigma)| = 1$, we have
\begin{align}
    \lambda u^\varepsilon(x_\sigma) - \lambda u_\delta(y_\sigma) &\leq \underbrace{\left|\frac{2\mathfrak{C}(x_\sigma-y_\sigma)}{\sigma}\right|^p}_{|\xi_\sigma|^p} - \underbrace{ \left|\frac{2\mathfrak{C}(x_\sigma-y_\sigma)}{\sigma} - \frac{C_\varepsilon(\alpha+\beta)}{d(x_\sigma)^{\alpha+\beta+1}}D d(x_\sigma )\right|^p}_{|\xi_\sigma+\zeta_\sigma|^p} \nonumber\\
    &+ \underbrace{f(y_\sigma) - f(x_\sigma)}_{\mathfrak{F}|x_\sigma - y_\sigma|} + \varepsilon\left(\frac{2n}{\sigma} + \underbrace{\frac{C_\varepsilon(\alpha+\beta)(\alpha+\beta+1)}{d(x_\sigma)^{\alpha+\beta+2}}}_{\frac{C_\varepsilon (\alpha+\beta)}{d(x_\sigma)^{\alpha+\beta + 1}}.\frac{\alpha+\beta+1}{d(x_\sigma)}}-\underbrace{\frac{C_\varepsilon(\alpha+\beta)}{d(x_\sigma)^{\alpha+\beta+1}}\Delta d(x_\sigma)}_{\frac{C_\varepsilon(\alpha+\beta)}{d(x_\sigma)^{\alpha+\beta+1}}.\Delta d(x_\sigma)}\right)\nonumber\\
    &\leq |\xi_\sigma|^p - |\xi_\sigma+\zeta_\sigma|^p + \mathfrak{F}\sigma + \frac{2n\varepsilon}{\sigma} + (\alpha+\beta+1)|\zeta_\sigma|\frac{\varepsilon}{\sigma} + K|\zeta_\sigma|\varepsilon \label{e:est3}
\end{align}
where we recall that $K = \max_{x\in \overline{\Omega}}\Delta d(x)$. Let's recall a simple estimate, let $f(t) = (x+ty)^p$ then
\begin{align*}
    f(1) - f(0) = \int_ 0^1 f'(s)\;ds = p\int_0^1 (x+sy)^{p-1}y\;ds,
\end{align*}
therefore
\begin{align*}
    \left||x+y|^p - |x|^p \right| &\leq p \left(\int_0^1 |x+sy|^{p-1}ds\right)|y|\\
    &\leq p\left(\int_0^1\Big(|x|+s|y|\Big)^{p-1}\;ds\right)|y| \leq  p\Big(|x|+|y|\Big)^{p-1}|y|.
\end{align*}
Using this for $x = \xi_\sigma$ and $y = \zeta_\sigma$ we deduce that
\begin{align}
    \Big||\xi_\sigma+\zeta_\sigma|^p - |\xi|^p\Big| &\leq p\Big(|\xi_\sigma|+|\zeta_\sigma|\Big)^{p-1}|\zeta_\sigma|\nonumber\\
    &\leq p\left(2\mathfrak{C} + \frac{(\alpha+1)^{\alpha+1}}{\alpha}\varepsilon^{\alpha+1 - \gamma(\alpha+1+\beta)}\right)^{p-1}\frac{(\alpha+1)^{\alpha+1}}{\alpha}\varepsilon^{\alpha+1 - \gamma(\alpha+1+\beta)}\nonumber\\
    &\leq \underbrace{\left(p\big(2\mathfrak{C} + \mathfrak{C}_\alpha\big)^{p-1} \mathfrak{C}_\alpha \right)}_{\mathfrak{B}}\varepsilon^{\alpha+1 - \gamma(\alpha+1+\beta)} \label{e:est2}
\end{align}
where we make use of \eqref{e:bddp_sigmaq_sigma}.
\paragraph{\textcolor{blue}{\textbf{Step 7. Combining stuffs.}}} From \eqref{e:est2} and \eqref{e:est3} and $\sigma = \varepsilon^\gamma$ we deduce that
\begin{align*}
    \lambda u^\varepsilon(x_\sigma) - \lambda u_\delta(y_\sigma) &\leq   \mathfrak{B}\varepsilon^{\alpha+1 - \gamma(\alpha+1+\beta)}+ \mathfrak{F}\varepsilon^\gamma + 2n \varepsilon^{1-\gamma}\\
    & + (\alpha+\beta + 1)\mathfrak{C}_\alpha \varepsilon^{\alpha+1 - \gamma(\alpha+1+\beta)} \varepsilon^{1-\gamma} + K\mathfrak{C}_\alpha\varepsilon^{\alpha+1 - \gamma(\alpha+1+\beta)} \varepsilon.
\end{align*}
Let us denote
\begin{equation*}
    \mathfrak{X}:= \max\Big\lbrace \mathfrak{B}, \mathfrak{F},2n, (\alpha+\beta+1)\mathfrak{C}_\alpha, K\mathfrak{C}_\alpha \Big\rbrace
\end{equation*}
then
\begin{equation*}
    \lambda u^\varepsilon(x_\sigma) - \lambda u_\delta(y_\sigma) \leq \mathfrak{X}\Big(\varepsilon^{\alpha+1-\gamma(\alpha+1+\beta)}+\varepsilon^\gamma+\varepsilon^{1-\gamma} + \varepsilon^{\alpha+2-\gamma(\alpha+2+\beta)}+\varepsilon^{\alpha+2-\gamma(\alpha+1+\beta)}\Big).
\end{equation*}
Take $\gamma = \frac{1}{2}$ to balance $\varepsilon^\gamma \approx \varepsilon^{1-\gamma}$ (\textcolor{blue}{which normally gives the rate $\sqrt{\varepsilon}$ for zero Dirichlet boundary problem}), we have
\begin{equation*}
    \begin{cases}
    \alpha+1 - \frac{1}{2}(\alpha+1+\beta) > \frac{1}{2}\vspace{3pt}\\
    \alpha+2 - \frac{1}{2}(\alpha+2+\beta) > \frac{1}{2}\vspace{3pt}\\
    \alpha+2 - \frac{1}{2}(\alpha+1+\beta) > \frac{1}{2}
    \end{cases} \qquad\Longleftrightarrow\qquad \begin{cases}
    \alpha+1-\beta > 1\\
    \alpha+2-\beta > 1\\
    \alpha+3-\beta > 1
    \end{cases}
\end{equation*}
which is always correct as long as $0 < \beta < \alpha$. We note that as $1<p<2$, we have $\alpha\in (0,\infty)$ and therefore such a choice of $\beta$ is always possible. We conclude that
\begin{equation}\label{e:crucial}
    \lambda u^\varepsilon(x_\sigma) - \lambda u_\delta(y_\sigma) \leq \mathfrak{X}\varepsilon^\frac{1}{2}
\end{equation}
where $\sigma = \varepsilon^\frac{1}{2}$. 
\paragraph{\textcolor{blue}{\textbf{Step 8. Deriving the conclusion}.}} Using $\Phi^\sigma(x_\sigma,y_\sigma)\geq \Phi^\sigma(x,x)$ for \textcolor{red}{all} $x\in \overline{\Omega}_\delta =  \overline{\Omega}_{2\sigma}$, we have
\begin{equation*}
    \lambda u^\varepsilon(x) - \lambda u_\delta(x) - \frac{C_\varepsilon}{d(x)^{\alpha+\beta}} \leq \Phi^\sigma(x_\sigma,y_\sigma) \leq \lambda u^\varepsilon(x_\sigma) - \lambda u_\delta(y_\sigma) \leq \mathfrak{X}\varepsilon^\frac{1}{2}.
\end{equation*}
Using $d(x)\geq 2\sigma = 2\varepsilon^{\frac{1}{2}}$ we deduce that
\begin{equation}\label{e:almost}
    \lambda u^\varepsilon(x) - \lambda u_\delta(x) \leq \mathfrak{X}\varepsilon^\frac{1}{2} + \frac{(\alpha+1)^{\alpha+1}}{2^{\alpha+\beta}\alpha}\varepsilon^{\alpha+1 - \frac{\alpha+\beta}{2}} \leq \tilde{\mathfrak{X}}\varepsilon^\frac{1}{2} \qquad \text{for all}\;x\in \overline{\Omega}_{2\sigma}
\end{equation}
where (we see that $\alpha+1 - \frac{\alpha+\beta}{2} = 1+ \frac{\alpha-\beta}{2} > 1$)
\begin{equation*}
    \tilde{\mathfrak{X}} = \max \left\lbrace\mathfrak{X}, \frac{(\alpha+1)^{\alpha+1}}{2^{\alpha+\beta}\alpha} \right\rbrace.
\end{equation*}
Finally, in the case of the ball, $\Omega_\delta = (1-\delta)\Omega$, by \cite[Theorem 1.5]{kim_state-constraint_2020} we know that, optimally,
\begin{equation}\label{e:citepaper}
    0\leq \lambda u_\delta(x) - \lambda u^0(x)\leq C_H\delta \qquad\text{for all}\; x\in \overline{\Omega}_\delta.
\end{equation}
From \eqref{e:almost} and \eqref{e:citepaper} and $\delta =2\sigma= 2\varepsilon^\frac{1}{2}$, and $u^\varepsilon \geq u^0$ from Theorem \ref{thm:qual} we deduce that
\begin{align*}
    \fbox{ $\displaystyle 0 \leq \lambda u^\varepsilon(x) - \lambda u^0(x) \leq \left(\tilde{\mathfrak{X}} + 2C_H\right)\sqrt{\varepsilon} \qquad\text{for all}\; x\in \overline{\Omega}_{2\sqrt{\varepsilon}}$.}
\end{align*}
It appears that the boundary layer is the strip
\begin{equation*}
    \Gamma_\varepsilon = \{x\in \Omega: 0<\mathrm\dist(x,\partial\Omega)< 2\sqrt{\varepsilon}\}.
\end{equation*}
\color{blue}
\textcolor{blue}{\textbf{The next questions and tasks:}}
\begin{enumerate}
    \item Check all the constants, make sure things are correct!
    \item It seems that $\sqrt{\varepsilon}$ is the best using this method. Now we can improve this by either:
    \begin{itemize}
        \item[(a)] Make the boundary layer to $\sqrt{\varepsilon}$ only, instead of $2\sqrt{\varepsilon}$.
        \item[(b)] \textcolor{red}{\textbf{Important.}} Generalize this to more general domain, possibly star-shaped domains where we can do scaling is fine (just my guess).
    \end{itemize}
    \item Other formulations of the doubling variable method here, for example, in the first step, it seems that making $\Phi^\sigma(x,y)\to  -\infty$ as $x\to \partial\Omega$ is "\emph{too wasteful}". One may need only to do something like
    \begin{equation*}
        \Phi^\sigma(x,y) < \Phi^\sigma(0,0) \qquad\text{if}\qquad d(x) < \;\text{something close to the boundary}.
    \end{equation*}
    Can we improve that to get a better rate? My guess is not even if we can improve this, since the dominating term coming from $\varepsilon^\gamma$ and $\varepsilon^{1-\gamma}$ later. Nevertheless, it maybe still interesting to see why and how the \emph{wasteful} formulation here can be improved.
    \item \textcolor{red}{\textbf{Important.}} Using nonlinear adjoint method.
    \item Now once we have some rate, can we do bootstrap to improve it as we discussed earlier (the simple ideas, ...)?
    \item \textcolor{red}{\textbf{Important.}} Can we find an example where $|u^\varepsilon - u^0| = \mathcal{O}(1)$ in the strip where $0<\mathrm{dist}(x,\partial\Omega)<2\sqrt{\varepsilon}$? Or can we even make more layers inside with more scales, as $|u^\varepsilon - u^0| = \mathcal{O}(1)$ is not possible near the boundary $\partial\Omega$.
\end{enumerate}
\color{black}


\newpage
\section{Rate of convergence via a simple idea}
\noindent Let $\Omega = B(0,1)$, the scaling and distance near boundary are the same, i.e., $(1-\delta)\Omega = \Omega_\delta$.

\noindent Let $u_\delta\in \rmC(\overline{\Omega}_\delta)$ be the state-constraint solution of the first-order equation, still $H(x,\varrho) = |\varrho|^p - f(x)$,
\begin{equation*}
    \begin{cases}
    \lambda u_\delta(x) + H(x,Du_\delta(x)) \leq 0 &\qquad\text{in}\;(1-\delta)\Omega,\\
    \lambda u_\delta(x) + H(x,Du_\delta(x)) \geq 0 &\qquad\text{on}\;(1-\delta)\overline{\Omega}.
    \end{cases}
\end{equation*}
We know that the optimal rate of convergence of $u_\delta$ to $u^0$ is given by (\cite{kim_state-constraint_2020})
\begin{equation*}
    0\leq u_\delta - u^0 \leq C\delta
\end{equation*}
where $C$ depends on $H$ only (\textcolor{red}{check this}). 

\noindent Let $g_{\varepsilon,\delta}(x) = u^\varepsilon(x)$ for $x\in \partial\Omega_\delta$ which is finite. We have $u_\delta\leq g_{\varepsilon,\delta}$ for all $\varepsilon$ and also for each fixed $\delta>0$ then
\begin{equation*}
    \lim_{\varepsilon\to 0} g_{\varepsilon,\delta}(x) = u_\delta(x).
\end{equation*}
On the domain $\Omega_\delta$, we consider the problem
\begin{equation*}
    \begin{cases}
    \mathcal{L}[v^\varepsilon] = 0 &\qquad\text{in}\;\Omega_\delta,\\
    v^\varepsilon = g_{\delta,\varepsilon} &\qquad\text{on}\;\partial\Omega_\delta.
    \end{cases}
\end{equation*}
Question: can we quantify $\Vert v^\varepsilon - u_\delta\Vert_{L^\infty}$ in term of $\varepsilon$?

\section{Rate of convergence via nonlinear adjoint method}



%\nocite{*}



\section{Questions and Ideas}
\begin{quest} [Jan 12, 2021] Why do we use the distance functions to get boundary estimates? 
\end{quest}

\begin{quest} [Jan 13, 2021] Maximum principle for sub-quadratic case.
\end{quest}

\begin{quest}[Jan 20, 2021] Here is an idea to estimate $\Vert u^\varepsilon - u^0\Vert_{L^\infty_{loc}(\Omega)}$. We start first by assuming star-shaped and consider
\begin{equation}\label{e:S_eta}
    \begin{cases}
    \lambda u_\eta^\varepsilon(x) + H(x,Du_\eta^\varepsilon(x)) - \varepsilon \Delta u_\eta^\varepsilon(x) = 0 &\qquad
    \text{in}\;(1-\eta)\Omega, \vspace{0cm}\\
    \qquad\qquad\qquad\qquad\qquad\qquad\;\, u^\varepsilon_\eta(x) = +\infty &\qquad
    \text{on}\;(1-\eta)\partial\Omega.
    \end{cases} \tag{$S_\eta$}
\end{equation}
Can we estimate $0\leq u^\varepsilon_\eta - u^\varepsilon \leq \omega(\varepsilon,\eta)$ and then chose $\eta = \omega'(\varepsilon)$ to conclude? One way is to approximate infinity boundary by finite boundary first, it may be too naive, but whatever! 
\begin{equation}\label{e:S_eta_m}
    \begin{cases}
    \lambda v_\eta^\varepsilon(x) + H(x,Dv_\eta^\varepsilon(x)) - \varepsilon \Delta v_\eta^\varepsilon(x) = 0 &\qquad
    \text{in}\;(1-\eta)\Omega, \vspace{0cm}\\
    \qquad\qquad\qquad\qquad\qquad\qquad\;\, v^\varepsilon_\eta(x) = m &\qquad
    \text{on}\;(1-\eta)\partial\Omega.
    \end{cases} \tag{$S_{\eta}^m$}
\end{equation}
In contrast, let us consider
\begin{equation}\label{e:S_0}
    \begin{cases}
    \lambda v^\varepsilon(x) + H(x,Dv^\varepsilon(x)) - \varepsilon \Delta v^\varepsilon(x) = 0 &\qquad
    \text{in}\;\Omega, \vspace{0cm}\\
    \qquad\qquad\qquad\qquad\qquad\qquad\;\, v^\varepsilon(x) = m &\qquad
    \text{on}\;\partial\Omega.
    \end{cases} \tag{$S^m$}
\end{equation}
How can we compare $v^\varepsilon$ and $v^\varepsilon_\eta$?
\end{quest}

\begin{appendices}



\section{Gradient bounds}
\subsection{Local interior gradient bound for elliptic equation}
Let $\Omega\subset \R^n$ be an open, bounded, connected set with $\rmC^2$ boundary and $H(x,p):\overline{\Omega}\times \R^n\rightarrow \mathbb{R}$ be a continuously differentiable Hamiltonian satisfying
\begin{equation}\label{eq:grow}
\lim_{|p\rightarrow \infty} \left(\frac{1}{2}H(x,p)^2 + D_xH(x,p)\cdot p\right) = +\infty \qquad\text{uniformly in}\;x\in \overline{\Omega}. \tag{H1}
\end{equation}
We consider the following equation
\begin{equation}\label{eq:C_eps}
    \lambda u^\varepsilon(x) + H(x,Du^\varepsilon(x)) - \varepsilon \Delta u^\varepsilon(x) = 0 \qquad\text{in}\;\Omega.
\end{equation}
Let $u^\varepsilon\in \rmC^2(\Omega)\cap \mathrm{C}^1(\overline{\Omega})$ be a bounded solution to \eqref{eq:C_eps}, say $|\lambda u^\varepsilon(x)| \leq C_1$ for all $x\in \overline{\Omega}$. In this section we show that an interior gradient bound also holds, i.e., if $x\mapsto|Du^\varepsilon(x)|$ has a maximum over $\overline{\Omega}$ at $x_0\in \Omega$ then $|Du^\varepsilon(x_0)| \leq C_2$ for all $x\in \Omega$. Here $C_1,C_2$ are independent of $\varepsilon>0$.\\


\noindent We will use the classical Bernstein's argument. Let $\varphi(x) = \frac{1}{2}|Du^\varepsilon(x)|^2$ for $x\in \Omega$. Differentiate \eqref{eq:C_eps} in $x_i$ then multiply the resulting equation with $u^\varepsilon_{x_i}$ and then sum over $i=1,2,\ldots, n$ we obtain 
\begin{equation*}
    2\lambda \varphi(x) + D_pH(x,Du^\varepsilon(x))\cdot D\varphi(x) - \varepsilon \Delta \varphi(x) + \Big(\varepsilon |D^2u^\varepsilon(x)| + D_xH(x,Du^\varepsilon(x))\cdot Du^\varepsilon(x)\Big) = 0.
\end{equation*}
If $\varphi(x)$ achieves its maximum over $\overline{\Omega}$ at $x_0\in \Omega$, then $D\varphi(x_0) = 0$ and $\Delta \varphi(x_0)\leq 0$, together with $\varepsilon |D^2u^\varepsilon(x)|^2\geq \frac{1}{n\varepsilon}(\varepsilon\Delta u^\varepsilon(x))^2\geq (\varepsilon\Delta u^\varepsilon(x))^2$ if $n\varepsilon < 1$ we deduce that
\begin{equation*}
    \lambda |D u^\varepsilon(x_0)|^2 + \Big(\lambda u^\varepsilon(x_0)+H(x_0,Du^\varepsilon(x_0))\Big)^2 + D_xH(x_0,Du^\varepsilon(x_0))\cdot Du^\varepsilon(x_0) \leq 0.
\end{equation*}
Assume $|\lambda u^\varepsilon(x_0)|\leq C_1$, using \eqref{eq:grow} we deduce that
\begin{equation*}
    \frac{1}{2}H(x_0,Du^\varepsilon(x_0))^2 + D_xH(x_0,Du^\varepsilon(x_0))\cdot Du^\varepsilon(x_0) + \left(\frac{1}{\sqrt{2}}H(x_0,Du^\varepsilon(x_0) - \sqrt{2}C_1\right)^2 - \left(C_1\right)^2\leq 0
\end{equation*}
which gives us $|Du^\varepsilon(x_0)|\leq C_2$ for some $C_2$ independent of $\varepsilon$. 
\begin{rem} Assumption \eqref{eq:grow} is weaker than the combination of $p\mapsto H(x,p)$ is superlinear and $|D_xH(x,p)|\leq C(1+|p|)$.
\end{rem}


\section{Differentiability with respect to the parameter}
For the vanishing viscosity problem with the Dirichlet boundary condition,
\begin{equation}
\label{dir}
\left\{
  \begin{aligned}
    H(x, Du^\epsilon(x)) &= \epsilon \Delta u^\epsilon \quad \, \text{in } U, \\
              u^\epsilon &= 0 \quad \qquad \text{on } \partial U,
  \end{aligned}
\right.
\end{equation}
where  $H(x,p)$ is $C^\infty(\overline{U}\times \mathbb{R}^n)$, $\displaystyle \frac{H(x,p)}{|p|} \to \infty$ uniformly in $x$ as $|p| \to \infty$ and $\displaystyle \sup_{x\in U}|D_xH(x,p)|\leq C(1+|p|)$, we want to show the smooth dependence of $u^\epsilon$ on $\epsilon$.
Formally, if we differentiate \eqref{dir} with respect to $\epsilon$, we get
\begin{equation}
\label{dir_dif}
\left\{
  \begin{aligned}
    D_pH(x, Du^\epsilon(x))\cdot Du^\epsilon_\epsilon &= \epsilon \Delta u^\epsilon_\epsilon +\Delta u^\epsilon \quad \, \text{in } U, \\
              u^\epsilon_\epsilon &= 0 \quad \qquad  \qquad  \text{on } \partial U.
  \end{aligned}
\right.
\end{equation}
By Schaefer's fixed point theorem and the maximal principle, $u^\epsilon_\epsilon$ is the unique solution in $C^{2,\alpha}(\overline{U})$ of \eqref{dir_dif}. 

\noindent The main idea is, we look at the difference quotients $\displaystyle \frac{u^{\epsilon+h}-u^\epsilon}{h}$and prove that as $h \to 0^+$, they converge to a limiting function $w^{\ast}$ in the uniform norm  such that $w^{\ast}$ solves \eqref{dir_dif}. Since \eqref{dir_dif} has a unique solution, we have $$u^\epsilon_\epsilon=\lim_{h \to 0^+}\frac{u^{\epsilon+h}-u^\epsilon}{h}.$$

\subsection{Solution $u^\epsilon \in C^{2,\alpha}(\overline{U})$ exists} We use Schaufer's fixed point theorem as follows.

\begin{thm} Suppose $X$ is a Banach space. Let $A:X \to X$ be continuous and compact. Assume the set $\{u\in X : u=\lambda A[u]$ for some $0 \leq  \lambda \leq 1\}$ is bounded. Then $A$ has a fixed point $u =A[u]$.
\end{thm}
\noindent Fix $0<\alpha<1$. Let $X=C^{1,\alpha}(\overline{U})$. Given $u \in X=C^{1,\alpha}(\overline{U})$, we look at the linear PDE
\begin{equation}
\label{fix}
\left\{
  \begin{aligned}
   \epsilon \Delta v &= H(x, Du) \quad \, \text{in } U, \\
              v &= 0 \qquad \qquad \text{on } \partial U.
  \end{aligned}
\right.
\end{equation}
\noindent
Estimate the Holder norm of RHS
$$\|H(x, Du)\|_{C^{0, \alpha}(\overline{U})}:=\sup_{x\in\overline{U}} |H(x,Du(x))| + \sup_{x, y \in \overline{U}}\frac{|H(x, Du(x))-H(y, Du(y))|}{|x-y|^\alpha}.$$
Since $Du$ is bounded and H is smooth,
\begin{equation}
    \sup_{x\in\overline{U}} |H(x,Du(x))| \leq C.
\end{equation}

\begin{equation}
    \begin{aligned}
  &\sup_{x, y \in \overline{U}}\frac{|H(x, Du(x))-H(y, Du(y))|}{|x-y|^\alpha}\\
  \leq &  \sup_{x, y \in \overline{U}}\frac{|H(x, Du(x))-H(y, Du(x))|}{|x-y|^\alpha} + \sup_{x, y \in \overline{U}}\frac{|H(y, Du(x))-H(y, Du(y))|}{|x-y|^\alpha} \\
  =&    \sup_{x, y \in \overline{U}}\frac{|\int_0^1D_xH(y+\theta (x-y), Du(x))d\theta \cdot (x-y)|}{|x-y|^\alpha}\\& +
     \sup_{x, y \in \overline{U}}\frac{|\int_0^1D_pH(y, Du(y)+\theta (Du(x)-Du(y)))d\theta \cdot (Du(x)-Du(y))|}{|x-y|^\alpha}\\
  \leq &  C\sup_{x, y \in \overline{U}} (1+|Du(x)|)|x-y|^{1-\alpha} +  C \sup_{x, y \in \overline{U}}\frac{| (Du(x)-Du(y))|}{|x-y|^\alpha}\\
 \leq & C(1 + \|u\|_{C^{1,\alpha}(\overline{U})})
    \end{aligned}
\end{equation}
since $Du$ is bounded on $\overline{U}$, $D_pH \in C^\infty (\overline{U} \times \mathbb{R}^n)$ and
$\displaystyle \sup_{x\in U}|D_xH(x,p)|\leq C(1+|p|)$. Therefore,
\begin{equation}
 \|H(x, Du)\|_{C^{0, \alpha}(\overline{U})} \leq C(1 + \|u\|_{C^{1,\alpha}(\overline{U})}).
\end{equation}
By Schauder estimates, there exists a unique solution $v \in C^{2,\alpha }(\overline{U})$ such that
\begin{equation}
\label{schauder}
    \|v\|_{C^{2, \alpha}(\overline{U})} \leq C  \|H(x, Du)\|_{C^{0, \alpha}(\overline{U})}. 
\end{equation}
\noindent Define operator $A$ on $X := C^{1, \alpha} (\overline{U}) $ by $A[u]=v$. So 
\begin{equation}
     \|A[u]\|_{C^{2, \alpha}(\overline{U})} \leq C(1 + \|u\|_{C^{1,\alpha}(\overline{U})}),
\end{equation}
\noindent
 and thus $A$ is continuous and compact. (i.e., if $\{u_k\}_{k=1}^\infty$ is bounded in $X=C^{1, \alpha}(\overline{U})$, then $\{A[u_k]\}_{k=1}\infty$ is bounded in $C^{2,\alpha} (\overline{U})$, thus precompact in $C^{1, \alpha}(\overline{U})$. Lemma 6.36 in Gilbarg and Trudinger. )
 
 Next we try to bound $\{u\in X : u=\lambda A[u]$ for some $0 \leq  \lambda \leq 1\}$.
 If $u=\lambda A[u]$, the PDE becomes
 
\begin{equation}
\label{lamb}
\left\{
  \begin{aligned}
   \epsilon \Delta u &= \lambda H(x, Du) \quad \, \text{in } U, \\
              u &= 0 \qquad \qquad \text{on } \partial U.
  \end{aligned}
\right.
\end{equation}

Calderon-Zygmund estimates tell us that if we have
\begin{equation}
\label{cald}
\left\{
  \begin{aligned}
  - \Delta v &=\Tilde{f}   \qquad \, \text{in } U, \\
              v &= 0 \qquad \text{on } \partial U.
  \end{aligned}
\right.
\end{equation}

and $\Tilde{f} \in {L^p(U)}$ for some $p\in (1, \infty)$, then $v \in W^{2,p}(U)$ and $$\|v\|_{w^{2,p}(U)} \leq C\|\Tilde{f}\|_{L^p(U)}.$$ 

Apply to \eqref{lamb} and we get

\begin{equation}
    \|u\|_{w^{2,p}(U)} \leq C\|H(x, Du)\|_{L^p(U)}
\end{equation}


(We want RHS to be bounded by some constant so that later we can choose $p$ larger than $n$ to  conclude $ \|u\|_{C^{1, \alpha}(U)} \leq   C\|u\|_{w^{2,p}(U)} \leq C$ by Morrey's estimate.) By a priori estimate, if we assume the solution of \eqref{dir} $u$ exists, then $\| Du\|_{L^\infty} \leq C_0$ where $C_0$ is independent of $\epsilon$. We can modify $H$ to get a new $\Tilde{H}$ so that it is smooth, $\Tilde{H} = H$ for $|p|<C_1$ and $H(x,p)=C_1+1$ for $|p|>C_1+1$ for some constant $C_1$ ($C_1$ is definitely larger than $C^0$). Moreover, the same prior estimate is correct for $\Tilde{H}$. Namely, if the solution $\Tilde{u}$ to \eqref{dir} with $H$ replaced by $\Tilde{H}$ exists, then $\| D\Tilde{u}\|_{L^\infty} \leq C_0$. (The way we choose this $C_1$ is that we work back from the beginning of the proof of a priori estimate for $u$, on both the boundary and interior of $\Omega$, and modify $H$ so that all the proofs go through and the same a priori estimate holds for the equation with $\Tilde{H}$.) Now with $\Tilde{H}$, we go through the same argument of Schaufer's fixed point theorem from the very beginning, and \eqref{cald} reads
\begin{equation}
       \|\Tilde{u}\|_{w^{2,p}(U)} \leq C\|\Tilde{H}(x, D\Tilde{u})\|_{L^p(U)} \leq C(1+\|D\Tilde{u}\|_{L^\infty}) \leq C.
\end{equation}

Choose $p=2n$ and $\displaystyle \alpha =\frac{1}{2}$. We have $\{\Tilde{u}\in X : \Tilde{u}=\lambda A[\Tilde{u}]$ for some $0 \leq  \lambda \leq 1\}$ is bounded in $X= C^{1, \frac{1}{2}}(
\overline{U})$.
Thus Schaefer's fixed point theorem implies the equation \eqref{dir} with $H$ replaced by $\Tilde{H}$ has a solution $\Tilde{u} \in C^{2,\alpha} (\overline{\Omega})$. Since $\| D\Tilde{u}\|_{L^\infty} \leq C_0$, $\Tilde{u}$ also solves the original equation \eqref{dir}.



\subsection{Uniqueness}
Let $u$ and $v$ be two solutions to \eqref{dir} and $w := u-v$. Then we have
\begin{equation}
\begin{aligned}
    &-\epsilon \Delta (u-v) = H(x, Dv)-H(x, Du)\\
    \Rightarrow &-\epsilon \Delta w   =\int_0^1 D_pH(x, tDv+(1-t)Du) \cdot (Dv-Du)dt\\
    \Rightarrow &-\epsilon \Delta w  +\int_0^1 D_pH(x, tDv+(1-t)Du)dt \cdot Dw = 0.
\end{aligned}
\end{equation}
By the strong maximum principle, $w \equiv 0$.



\subsection{Smooth dependence on $\epsilon$}
Fix $\epsilon >0$. Let  $$w^h(x):=\frac{u^{\epsilon+h}(x)-u^\epsilon(x)}{h} \in C^{2,\alpha}(\overline{U}).$$

A little computation shows that $w^h$ solves

\begin{equation}
\label{dir_quo}
\left\{
  \begin{aligned}
   \epsilon \Delta w^h(x) + \frac{\epsilon}{\epsilon + h}\Delta u^\epsilon &= \frac{\epsilon}{\epsilon +h} \int_0^1 D_pH(x, Du^\epsilon+\theta (Du^{\epsilon+h}-Du^\epsilon)) d\theta \cdot Dw^h \quad \, \text{in } U, \\
              w^h &= 0 \quad \qquad \text{on } \partial U.
  \end{aligned}
\right.
\end{equation}

From the existence proof, we know $\|u^\epsilon\|_{C^{2,\alpha}(\overline{U})} \leq C$ uniformly in $\epsilon$. So $\|Du^{\epsilon+h}-Du^\epsilon\|_{C^{0,\alpha}(\overline{U})}$and $\|\Delta u\|_{C^{0,\alpha}(\overline{U})}
$ is uniformly bounded in $h$.  

By Schauder estimates, $\{w^h\}_{h>0} \subset C^{2, \alpha}(\overline{U})$ are bounded, hence is precompact in $ C^{2, \beta}(\overline{U})$ for any $\beta < \alpha$. Therefore, there exits a subsequence $\{w^{h_j}\}_{j=1}^\infty$ such that $w^{h_j} \to w^\ast$ for some $w^\ast \in  C^{2, \beta}(\overline{U}) $ and $w^\ast$ solves \eqref{dir_dif}. This implies $w^h \to w^\ast$ in $C^{2, \beta}(\overline{U})$.


\section{Proofs of some Lemmas and Propositions}
\begin{proof}[Proof of Lemma \ref{lem:max}] The proof is a variation of Perron's method (see \cite{Capuzzo-Dolcetta1990}). Let $\varphi\in \rmC(\overline{\Omega})$ and $x_0\in \overline{\Omega}$ such that $u(x_0) = \varphi(x_0)$ and $u-\varphi$ has a global strict minimum over $\overline{\Omega}$ at $x_0$ and that 
\begin{equation}\label{eq:max_a1}
    \lambda \varphi(x_0) + H(x_0,D\varphi(x_0)) < 0.
\end{equation}
Let $\varphi^\varepsilon(x) = \varphi(x) - |x-x_0|^2 + \varepsilon$ for $x\in \overline{\Omega}$. Let $\delta > 0$, we see that for $x\in \partial B(x_0,\delta)\cap \overline{\Omega}$ then
\begin{equation*}
    \varphi^\varepsilon(x) = \varphi(x) - \delta^2 +\varepsilon \leq \varphi(x) - \varepsilon
\end{equation*}
if $2\varepsilon \leq \delta^2$. We observe that
\begin{equation*}
    \begin{split}
    \varphi^\varepsilon(x) - \varphi(x_0)  &= \varphi(x)-\varphi(x_0) + \varepsilon - |x-x_0|^2 \\
    D\phi^\varepsilon(x) - D\phi(x_0) &= D\varphi(x) - D\varphi(x_0) - 2(x-x_0)
    \end{split}
\end{equation*}
for $x\in B(x,\delta)\cap \overline{\Omega}$. We deduce from \eqref{eq:max_a1}, the continuity of $H(x,p)$ near $(x_0,D\varphi(x_0))$ and the fact that $\varphi\in \rmC^1(\overline{\Omega})$ that if $\delta$ is small enough and $0<2\varepsilon < \delta^2$ then
\begin{equation}\label{eq:max_a2}
    \lambda \varphi^\varepsilon(x)+H(x,D\varphi^\varepsilon(x)) < 0 \qquad\text{for}\;x\in B(x_0,\delta)\cap \overline{\Omega}.
\end{equation}
We have found $\phi^\varepsilon\in \mathrm{C}^1(\overline{\Omega})$ such that $\varphi^\varepsilon(x_0)>u(x_0)$, $\varphi^\varepsilon<u$ on $\partial B(x_0,\delta)\cap \overline{\Omega}$ and \eqref{eq:max_a2}. Let
\begin{equation*}
    \tilde{u}(x) = \begin{cases}
    \max \big\lbrace u(x),\phi^\varepsilon(x) \big\rbrace &x\in B(x_0,\delta)\cap \overline{\Omega},\\
    u(x)&x\notin B(x_0,\delta)\cap \overline{\Omega},\\
    \end{cases}
\end{equation*}
We see that $\tilde{u}\in \rmC(\overline{\Omega})$ is a subsolution of \eqref{S_0} in $\Omega$ with $\tilde{u}(x_0) > u(x_0)$, which is a contradiction, thus $u$ is a supersolution of \eqref{S_0} on $\overline{\Omega}$.
\end{proof}

\end{appendices}

%\section*{Acknowledgement}




\bibliography{zzzzlibrary}{}
%\bibliographystyle{ieeetr}
\bibliographystyle{acm}










\end{document}